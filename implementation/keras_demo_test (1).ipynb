{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "71KIDaovPASn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 128\n",
    "num_samples = 127606\n",
    "filename = 'English_hindi.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sgUhidzEUZdA"
   },
   "outputs": [],
   "source": [
    "# vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = []\n",
    "target_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype(x):\n",
    "    if not x:\n",
    "        return ''\n",
    "    try:\n",
    "        return str(x)   \n",
    "    except:        \n",
    "        return ''\n",
    "    \n",
    "df = pd.read_csv(filename , converters={'English': convert_dtype,'Hindi': convert_dtype})\n",
    "input_texts = df['English'].values.tolist()\n",
    "target_texts = df['Hindi'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_texts)):\n",
    "    target_texts[i] = '\\t' + target_texts[i] + '\\n'\n",
    "    for char in input_texts[i]:\n",
    "        if char not in input_characters:\n",
    "            input_characters.append(char)\n",
    "    for char in target_texts[i]:\n",
    "        if char not in target_characters:\n",
    "            target_characters.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2SzPIOK4UnMM"
   },
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_len = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_len = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4i-vFE-Uux5",
    "outputId": "5402f339-7a17-4c31-ec86-fbee4a093bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i/p characters : 180\n",
      "targert characters : 245\n",
      "encoder characters : 180\n",
      "decoder characters : 245\n",
      "max encoder : 2239\n",
      "max decoder : 2046\n"
     ]
    }
   ],
   "source": [
    "print('i/p characters : {}'.format(len(input_characters)))\n",
    "print('targert characters : {}'.format(len(target_characters)))\n",
    "print('encoder characters : {}'.format(num_encoder_tokens))\n",
    "print('decoder characters : {}'.format(num_decoder_tokens))\n",
    "print('max encoder : {}'.format(max_encoder_seq_len))\n",
    "print('max decoder : {}'.format(max_decoder_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9I4qgaOpUz8t",
    "outputId": "125ad5e8-033b-4562-ed7a-2feef17c31f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, '@': 32, 'A': 33, 'B': 34, 'C': 35, 'D': 36, 'E': 37, 'F': 38, 'G': 39, 'H': 40, 'I': 41, 'J': 42, 'K': 43, 'L': 44, 'M': 45, 'N': 46, 'O': 47, 'P': 48, 'Q': 49, 'R': 50, 'S': 51, 'T': 52, 'U': 53, 'V': 54, 'W': 55, 'X': 56, 'Y': 57, 'Z': 58, '[': 59, '\\\\': 60, ']': 61, '^': 62, '_': 63, '`': 64, 'a': 65, 'b': 66, 'c': 67, 'd': 68, 'e': 69, 'f': 70, 'g': 71, 'h': 72, 'i': 73, 'j': 74, 'k': 75, 'l': 76, 'm': 77, 'n': 78, 'o': 79, 'p': 80, 'q': 81, 'r': 82, 's': 83, 't': 84, 'u': 85, 'v': 86, 'w': 87, 'x': 88, 'y': 89, 'z': 90, '{': 91, '|': 92, '}': 93, '~': 94, '£': 95, '°': 96, '±': 97, '²': 98, 'µ': 99, '½': 100, 'Á': 101, 'É': 102, 'Í': 103, 'á': 104, 'é': 105, 'í': 106, 'ó': 107, 'ā': 108, 'ē': 109, 'ī': 110, 'ō': 111, 'ś': 112, 'š': 113, 'μ': 114, 'ँ': 115, 'ं': 116, 'ः': 117, 'अ': 118, 'आ': 119, 'इ': 120, 'ई': 121, 'ऋ': 122, 'ए': 123, 'औ': 124, 'क': 125, 'ख': 126, 'ग': 127, 'घ': 128, 'च': 129, 'ज': 130, 'ञ': 131, 'ट': 132, 'ठ': 133, 'ण': 134, 'त': 135, 'थ': 136, 'द': 137, 'न': 138, 'प': 139, 'ब': 140, 'भ': 141, 'म': 142, 'य': 143, 'र': 144, 'ल': 145, 'व': 146, 'श': 147, 'ष': 148, 'स': 149, 'ह': 150, 'ा': 151, 'ि': 152, 'ी': 153, 'ु': 154, 'ू': 155, 'ृ': 156, 'े': 157, 'ै': 158, 'ो': 159, '्': 160, 'চ': 161, 'দ': 162, 'ন': 163, 'ব': 164, 'ভ': 165, 'র': 166, 'ষ': 167, 'স': 168, 'া': 169, 'ু': 170, '্': 171, '‘': 172, '“': 173, '”': 174, '€': 175, '⅔': 176, '☺': 177, '☻': 178, '♫': 179}\n",
      "{'\\t': 0, '\\n': 1, '\\x14': 2, ' ': 3, '!': 4, '\"': 5, '#': 6, '$': 7, '%': 8, '&': 9, \"'\": 10, '(': 11, ')': 12, '*': 13, '+': 14, ',': 15, '-': 16, '.': 17, '/': 18, '0': 19, '1': 20, '2': 21, '3': 22, '4': 23, '5': 24, '6': 25, '7': 26, '8': 27, '9': 28, ':': 29, ';': 30, '<': 31, '=': 32, '>': 33, '?': 34, '@': 35, 'A': 36, 'B': 37, 'C': 38, 'D': 39, 'E': 40, 'F': 41, 'G': 42, 'H': 43, 'I': 44, 'J': 45, 'K': 46, 'L': 47, 'M': 48, 'N': 49, 'O': 50, 'P': 51, 'Q': 52, 'R': 53, 'S': 54, 'T': 55, 'U': 56, 'V': 57, 'W': 58, 'X': 59, 'Y': 60, 'Z': 61, '[': 62, '\\\\': 63, ']': 64, '^': 65, '_': 66, '`': 67, 'a': 68, 'b': 69, 'c': 70, 'd': 71, 'e': 72, 'f': 73, 'g': 74, 'h': 75, 'i': 76, 'j': 77, 'k': 78, 'l': 79, 'm': 80, 'n': 81, 'o': 82, 'p': 83, 'q': 84, 'r': 85, 's': 86, 't': 87, 'u': 88, 'v': 89, 'w': 90, 'x': 91, 'y': 92, 'z': 93, '{': 94, '|': 95, '}': 96, '~': 97, '¥': 98, '¬': 99, '°': 100, '±': 101, '²': 102, '³': 103, '·': 104, 'º': 105, '¼': 106, '½': 107, '́': 108, '̃': 109, '̄': 110, '̈': 111, 'μ': 112, 'ا': 113, 'ت': 114, 'ج': 115, 'ح': 116, 'ر': 117, 'س': 118, 'ق': 119, 'ل': 120, 'م': 121, 'ن': 122, 'ٓ': 123, 'ٕ': 124, 'ँ': 125, 'ं': 126, 'ः': 127, 'अ': 128, 'आ': 129, 'इ': 130, 'ई': 131, 'उ': 132, 'ऊ': 133, 'ऋ': 134, 'ऌ': 135, 'ऍ': 136, 'ऎ': 137, 'ए': 138, 'ऐ': 139, 'ऑ': 140, 'ऒ': 141, 'ओ': 142, 'औ': 143, 'क': 144, 'ख': 145, 'ग': 146, 'घ': 147, 'ङ': 148, 'च': 149, 'छ': 150, 'ज': 151, 'झ': 152, 'ञ': 153, 'ट': 154, 'ठ': 155, 'ड': 156, 'ढ': 157, 'ण': 158, 'त': 159, 'थ': 160, 'द': 161, 'ध': 162, 'न': 163, 'प': 164, 'फ': 165, 'ब': 166, 'भ': 167, 'म': 168, 'य': 169, 'र': 170, 'ल': 171, 'ळ': 172, 'व': 173, 'श': 174, 'ष': 175, 'स': 176, 'ह': 177, '़': 178, 'ऽ': 179, 'ा': 180, 'ि': 181, 'ी': 182, 'ु': 183, 'ू': 184, 'ृ': 185, 'ॄ': 186, 'ॅ': 187, 'ॆ': 188, 'े': 189, 'ै': 190, 'ॉ': 191, 'ॊ': 192, 'ो': 193, 'ौ': 194, '्': 195, 'ॐ': 196, '॑': 197, '॓': 198, 'ॠ': 199, 'ॡ': 200, '।': 201, '॥': 202, '०': 203, '१': 204, '२': 205, '३': 206, '४': 207, '५': 208, '६': 209, '७': 210, '८': 211, '९': 212, '॰': 213, 'ক': 214, 'চ': 215, 'ঠ': 216, 'থ': 217, 'দ': 218, 'ন': 219, 'ব': 220, 'ভ': 221, 'র': 222, 'ষ': 223, 'স': 224, 'া': 225, 'ী': 226, 'ু': 227, '্': 228, '\\u200b': 229, '\\u200c': 230, '\\u200e': 231, '‘': 232, '“': 233, '”': 234, '†': 235, '…': 236, '™': 237, '⇒': 238, '☺': 239, '☻': 240, '♫': 241, '中': 242, '國': 243, '秦': 244}\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])\n",
    "print(input_token_index)\n",
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wmBpRsSzVD7G"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 192. GiB for an array with shape (127607, 2239, 180) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c7e427c11188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_encoder_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_encoder_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_decoder_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_decoder_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 192. GiB for an array with shape (127607, 2239, 180) and data type float32"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_len, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfXHofhPVInE"
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t+1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]] = 1.\n",
    "    decoder_input_data[i,t+1:,target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i,t:,target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ptYGuw0VOtS",
    "outputId": "9176a793-0755-48fc-c453-0835128fff03"
   },
   "outputs": [],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG-LYA-zVSqA"
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it\n",
    "encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
    "encoder=LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs, state_h, state_c=encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNhgkKDNVXs-"
   },
   "outputs": [],
   "source": [
    "# Set up decoder , using ` encoder_states` as initial state\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well . we don't use the \n",
    "# return states in the training model , but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense= Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs= decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh4zcfy0VdFT",
    "outputId": "1541bd55-d190-4a0b-e1c2-816009690dc7"
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn \n",
    "# `encoder_input_data` and `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size= batch_size, epochs = epochs , \n",
    "           validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2uFKYKZVgVz"
   },
   "outputs": [],
   "source": [
    "#model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEYC65TCmO_n"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SwDtX4RmRq0"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZeNJ0P5mVhm",
    "outputId": "002732a4-8918-431a-e55c-67f7ef334ca0"
   },
   "outputs": [],
   "source": [
    "for seq_index in range(20):\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print(input_texts[seq_index])\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1u0onnyUmY_6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "keras_demo_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

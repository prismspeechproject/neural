{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_demo_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "71KIDaovPASn"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "epochs = 100\r\n",
        "latent_dim = 256\r\n",
        "num_samples = 2700\r\n",
        "filename = 'cl.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgUhidzEUZdA"
      },
      "source": [
        "# vectorize the data\r\n",
        "input_texts = []\r\n",
        "target_texts = []\r\n",
        "input_characters = []\r\n",
        "target_characters = []\r\n",
        "\r\n",
        "df = pd.read_csv(filename)\r\n",
        "input_texts = df['English'].values.tolist()\r\n",
        "target_texts = df['Hindi'].values.tolist()\r\n",
        "\r\n",
        "for i in range(len(target_texts)):\r\n",
        "    target_texts[i] = '\\t' + target_texts[i] + '\\n'\r\n",
        "    for char in input_texts[i]:\r\n",
        "        if char not in input_characters:\r\n",
        "            input_characters.append(char)\r\n",
        "    for char in target_texts[i]:\r\n",
        "        if char not in target_characters:\r\n",
        "            target_characters.append(char)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SzPIOK4UnMM"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\r\n",
        "target_characters = sorted(list(target_characters))\r\n",
        "num_encoder_tokens = len(input_characters)\r\n",
        "num_decoder_tokens = len(target_characters)\r\n",
        "max_encoder_seq_len = max([len(txt) for txt in input_texts])\r\n",
        "max_decoder_seq_len = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4i-vFE-Uux5",
        "outputId": "5402f339-7a17-4c31-ec86-fbee4a093bec"
      },
      "source": [
        "print('i/p characters : {}'.format(len(input_characters)))\r\n",
        "print('targert characters : {}'.format(len(target_characters)))\r\n",
        "print('encoder characters : {}'.format(num_encoder_tokens))\r\n",
        "print('decoder characters : {}'.format(num_decoder_tokens))\r\n",
        "print('max encoder : {}'.format(max_encoder_seq_len))\r\n",
        "print('max decoder : {}'.format(max_decoder_seq_len))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i/p characters : 70\n",
            "targert characters : 87\n",
            "encoder characters : 70\n",
            "decoder characters : 87\n",
            "max encoder : 107\n",
            "max decoder : 123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I4qgaOpUz8t",
        "outputId": "125ad5e8-033b-4562-ed7a-2feef17c31f9"
      },
      "source": [
        "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\r\n",
        "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])\r\n",
        "print(input_token_index)\r\n",
        "print(target_token_index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '$': 3, \"'\": 4, ',': 5, '-': 6, '.': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17, ':': 18, '?': 19, 'A': 20, 'B': 21, 'C': 22, 'D': 23, 'E': 24, 'F': 25, 'G': 26, 'H': 27, 'I': 28, 'J': 29, 'K': 30, 'L': 31, 'M': 32, 'N': 33, 'O': 34, 'P': 35, 'Q': 36, 'R': 37, 'S': 38, 'T': 39, 'U': 40, 'V': 41, 'W': 42, 'Y': 43, 'a': 44, 'b': 45, 'c': 46, 'd': 47, 'e': 48, 'f': 49, 'g': 50, 'h': 51, 'i': 52, 'j': 53, 'k': 54, 'l': 55, 'm': 56, 'n': 57, 'o': 58, 'p': 59, 'q': 60, 'r': 61, 's': 62, 't': 63, 'u': 64, 'v': 65, 'w': 66, 'x': 67, 'y': 68, 'z': 69}\n",
            "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '5': 10, ':': 11, '?': 12, 'I': 13, '|': 14, 'ँ': 15, 'ं': 16, 'ः': 17, 'अ': 18, 'आ': 19, 'इ': 20, 'ई': 21, 'उ': 22, 'ऊ': 23, 'ऋ': 24, 'ए': 25, 'ऐ': 26, 'ऑ': 27, 'ओ': 28, 'औ': 29, 'क': 30, 'ख': 31, 'ग': 32, 'घ': 33, 'च': 34, 'छ': 35, 'ज': 36, 'झ': 37, 'ञ': 38, 'ट': 39, 'ठ': 40, 'ड': 41, 'ढ': 42, 'ण': 43, 'त': 44, 'थ': 45, 'द': 46, 'ध': 47, 'न': 48, 'प': 49, 'फ': 50, 'ब': 51, 'भ': 52, 'म': 53, 'य': 54, 'र': 55, 'ल': 56, 'व': 57, 'श': 58, 'ष': 59, 'स': 60, 'ह': 61, '़': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॅ': 69, 'े': 70, 'ै': 71, 'ॉ': 72, 'ो': 73, 'ौ': 74, '्': 75, '।': 76, '०': 77, '१': 78, '२': 79, '४': 80, '५': 81, '६': 82, '७': 83, '८': 84, '९': 85, '\\u200d': 86}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmBpRsSzVD7G"
      },
      "source": [
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_len, num_encoder_tokens), dtype='float32')\r\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')\r\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfXHofhPVInE"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\r\n",
        "    for t, char in enumerate(input_text):\r\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\r\n",
        "    encoder_input_data[i, t+1:, input_token_index[' ']] = 1.\r\n",
        "    for t, char in enumerate(target_text):\r\n",
        "        decoder_input_data[i,t,target_token_index[char]] = 1.\r\n",
        "        if t > 0:\r\n",
        "            decoder_target_data[i,t-1,target_token_index[char]] = 1.\r\n",
        "    decoder_input_data[i,t+1:,target_token_index[' ']] = 1.\r\n",
        "    decoder_target_data[i,t:,target_token_index[' ']] = 1."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ptYGuw0VOtS",
        "outputId": "9176a793-0755-48fc-c453-0835128fff03"
      },
      "source": [
        "encoder_input_data[0].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-LYA-zVSqA"
      },
      "source": [
        "# Define an input sequence and process it\r\n",
        "encoder_inputs = Input(shape=(None,num_encoder_tokens))\r\n",
        "encoder=LSTM(latent_dim,return_state=True)\r\n",
        "encoder_outputs, state_h, state_c=encoder(encoder_inputs)\r\n",
        "# We discard `encoder_outputs` and only keep the states\r\n",
        "encoder_states=[state_h,state_c]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNhgkKDNVXs-"
      },
      "source": [
        "# Set up decoder , using ` encoder_states` as initial state\r\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\r\n",
        "# We set up our decoder to return full output sequences,\r\n",
        "# and to return internal states as well . we don't use the \r\n",
        "# return states in the training model , but we will use them in inference.\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\r\n",
        "decoder_dense= Dense(num_decoder_tokens, activation='softmax')\r\n",
        "decoder_outputs= decoder_dense(decoder_outputs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh4zcfy0VdFT",
        "outputId": "1541bd55-d190-4a0b-e1c2-816009690dc7"
      },
      "source": [
        "# Define the model that will turn \r\n",
        "# `encoder_input_data` and `decoder_input_data` into `decoder_target_data`\r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\r\n",
        "\r\n",
        "# Run training\r\n",
        "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics= ['accuracy'])\r\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size= batch_size, epochs = epochs , \r\n",
        "           validation_split=0.2)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 42s 1s/step - loss: 1.7573 - accuracy: 0.7125 - val_loss: 1.6320 - val_accuracy: 0.6896\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.9785 - accuracy: 0.8071 - val_loss: 1.3610 - val_accuracy: 0.6897\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.8524 - accuracy: 0.8084 - val_loss: 1.9723 - val_accuracy: 0.6892\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.8200 - accuracy: 0.8083 - val_loss: 1.4358 - val_accuracy: 0.6901\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.7650 - accuracy: 0.8122 - val_loss: 1.2542 - val_accuracy: 0.6952\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.7256 - accuracy: 0.8195 - val_loss: 1.1655 - val_accuracy: 0.7054\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.6996 - accuracy: 0.8289 - val_loss: 1.1083 - val_accuracy: 0.7206\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.6403 - accuracy: 0.8397 - val_loss: 1.0351 - val_accuracy: 0.7336\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.6007 - accuracy: 0.8463 - val_loss: 0.9987 - val_accuracy: 0.7377\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.5694 - accuracy: 0.8541 - val_loss: 0.9594 - val_accuracy: 0.7482\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.5386 - accuracy: 0.8594 - val_loss: 0.9503 - val_accuracy: 0.7509\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.5276 - accuracy: 0.8611 - val_loss: 0.9108 - val_accuracy: 0.7595\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.5109 - accuracy: 0.8653 - val_loss: 0.9002 - val_accuracy: 0.7600\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.5074 - accuracy: 0.8653 - val_loss: 0.8837 - val_accuracy: 0.7677\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4865 - accuracy: 0.8711 - val_loss: 0.8600 - val_accuracy: 0.7705\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4801 - accuracy: 0.8717 - val_loss: 0.8712 - val_accuracy: 0.7694\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4734 - accuracy: 0.8732 - val_loss: 0.8394 - val_accuracy: 0.7748\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 39s 1s/step - loss: 0.4656 - accuracy: 0.8742 - val_loss: 0.8294 - val_accuracy: 0.7774\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 40s 1s/step - loss: 0.4611 - accuracy: 0.8742 - val_loss: 0.8278 - val_accuracy: 0.7770\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 39s 1s/step - loss: 0.4482 - accuracy: 0.8766 - val_loss: 0.8237 - val_accuracy: 0.7782\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4450 - accuracy: 0.8775 - val_loss: 0.8105 - val_accuracy: 0.7799\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 39s 1s/step - loss: 0.4323 - accuracy: 0.8804 - val_loss: 0.8049 - val_accuracy: 0.7804\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4287 - accuracy: 0.8812 - val_loss: 0.7950 - val_accuracy: 0.7825\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4183 - accuracy: 0.8832 - val_loss: 0.7925 - val_accuracy: 0.7834\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4108 - accuracy: 0.8848 - val_loss: 0.7768 - val_accuracy: 0.7883\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4129 - accuracy: 0.8842 - val_loss: 0.7839 - val_accuracy: 0.7855\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.4058 - accuracy: 0.8863 - val_loss: 0.7780 - val_accuracy: 0.7867\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3977 - accuracy: 0.8886 - val_loss: 0.7652 - val_accuracy: 0.7907\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3883 - accuracy: 0.8910 - val_loss: 0.7634 - val_accuracy: 0.7920\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3894 - accuracy: 0.8904 - val_loss: 0.7735 - val_accuracy: 0.7901\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3816 - accuracy: 0.8930 - val_loss: 0.7578 - val_accuracy: 0.7913\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3729 - accuracy: 0.8951 - val_loss: 0.7622 - val_accuracy: 0.7930\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3660 - accuracy: 0.8968 - val_loss: 0.7609 - val_accuracy: 0.7927\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3625 - accuracy: 0.8978 - val_loss: 0.7612 - val_accuracy: 0.7934\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3591 - accuracy: 0.8986 - val_loss: 0.7570 - val_accuracy: 0.7962\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3536 - accuracy: 0.9000 - val_loss: 0.7604 - val_accuracy: 0.7948\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3428 - accuracy: 0.9033 - val_loss: 0.7629 - val_accuracy: 0.7951\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3353 - accuracy: 0.9052 - val_loss: 0.7627 - val_accuracy: 0.7951\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3329 - accuracy: 0.9058 - val_loss: 0.7533 - val_accuracy: 0.7962\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3301 - accuracy: 0.9070 - val_loss: 0.7525 - val_accuracy: 0.7973\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3276 - accuracy: 0.9071 - val_loss: 0.7544 - val_accuracy: 0.7977\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3246 - accuracy: 0.9078 - val_loss: 0.7597 - val_accuracy: 0.7951\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3219 - accuracy: 0.9087 - val_loss: 0.7717 - val_accuracy: 0.7940\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3084 - accuracy: 0.9127 - val_loss: 0.7783 - val_accuracy: 0.7936\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 37s 1s/step - loss: 0.3052 - accuracy: 0.9137 - val_loss: 0.7767 - val_accuracy: 0.7943\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3012 - accuracy: 0.9145 - val_loss: 0.7717 - val_accuracy: 0.7954\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.3000 - accuracy: 0.9160 - val_loss: 0.7696 - val_accuracy: 0.7962\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2872 - accuracy: 0.9194 - val_loss: 0.7807 - val_accuracy: 0.7942\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2832 - accuracy: 0.9198 - val_loss: 0.7917 - val_accuracy: 0.7906\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2803 - accuracy: 0.9209 - val_loss: 0.7995 - val_accuracy: 0.7918\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2784 - accuracy: 0.9214 - val_loss: 0.7807 - val_accuracy: 0.7955\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2710 - accuracy: 0.9241 - val_loss: 0.8033 - val_accuracy: 0.7903\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2706 - accuracy: 0.9241 - val_loss: 0.8111 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2617 - accuracy: 0.9266 - val_loss: 0.8067 - val_accuracy: 0.7935\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2569 - accuracy: 0.9277 - val_loss: 0.8250 - val_accuracy: 0.7894\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 37s 1s/step - loss: 0.2534 - accuracy: 0.9292 - val_loss: 0.8142 - val_accuracy: 0.7924\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2474 - accuracy: 0.9308 - val_loss: 0.8211 - val_accuracy: 0.7912\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2452 - accuracy: 0.9315 - val_loss: 0.8340 - val_accuracy: 0.7900\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2346 - accuracy: 0.9352 - val_loss: 0.8380 - val_accuracy: 0.7901\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2332 - accuracy: 0.9347 - val_loss: 0.8457 - val_accuracy: 0.7891\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2320 - accuracy: 0.9351 - val_loss: 0.8549 - val_accuracy: 0.7884\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2280 - accuracy: 0.9368 - val_loss: 0.8574 - val_accuracy: 0.7875\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2231 - accuracy: 0.9381 - val_loss: 0.8668 - val_accuracy: 0.7864\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2155 - accuracy: 0.9402 - val_loss: 0.8811 - val_accuracy: 0.7870\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2186 - accuracy: 0.9390 - val_loss: 0.8892 - val_accuracy: 0.7857\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2144 - accuracy: 0.9407 - val_loss: 0.8888 - val_accuracy: 0.7870\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2066 - accuracy: 0.9429 - val_loss: 0.8860 - val_accuracy: 0.7896\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.2028 - accuracy: 0.9441 - val_loss: 0.9016 - val_accuracy: 0.7863\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1983 - accuracy: 0.9453 - val_loss: 0.9165 - val_accuracy: 0.7849\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1952 - accuracy: 0.9463 - val_loss: 0.9220 - val_accuracy: 0.7853\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1912 - accuracy: 0.9473 - val_loss: 0.9365 - val_accuracy: 0.7853\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1887 - accuracy: 0.9483 - val_loss: 0.9284 - val_accuracy: 0.7835\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1867 - accuracy: 0.9491 - val_loss: 0.9480 - val_accuracy: 0.7839\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1845 - accuracy: 0.9495 - val_loss: 0.9476 - val_accuracy: 0.7833\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1803 - accuracy: 0.9509 - val_loss: 0.9539 - val_accuracy: 0.7850\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1780 - accuracy: 0.9513 - val_loss: 0.9589 - val_accuracy: 0.7838\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1723 - accuracy: 0.9534 - val_loss: 0.9624 - val_accuracy: 0.7849\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1700 - accuracy: 0.9543 - val_loss: 0.9737 - val_accuracy: 0.7837\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1681 - accuracy: 0.9543 - val_loss: 1.0057 - val_accuracy: 0.7806\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1651 - accuracy: 0.9552 - val_loss: 0.9851 - val_accuracy: 0.7837\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1632 - accuracy: 0.9561 - val_loss: 1.0016 - val_accuracy: 0.7827\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1610 - accuracy: 0.9563 - val_loss: 1.0040 - val_accuracy: 0.7827\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1575 - accuracy: 0.9576 - val_loss: 1.0264 - val_accuracy: 0.7823\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1552 - accuracy: 0.9585 - val_loss: 1.0261 - val_accuracy: 0.7825\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1502 - accuracy: 0.9598 - val_loss: 1.0380 - val_accuracy: 0.7820\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1486 - accuracy: 0.9602 - val_loss: 1.0382 - val_accuracy: 0.7817\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1464 - accuracy: 0.9610 - val_loss: 1.0540 - val_accuracy: 0.7813\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1450 - accuracy: 0.9611 - val_loss: 1.0454 - val_accuracy: 0.7817\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1428 - accuracy: 0.9619 - val_loss: 1.0783 - val_accuracy: 0.7804\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1393 - accuracy: 0.9629 - val_loss: 1.0773 - val_accuracy: 0.7805\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1365 - accuracy: 0.9640 - val_loss: 1.0779 - val_accuracy: 0.7817\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1371 - accuracy: 0.9639 - val_loss: 1.0901 - val_accuracy: 0.7818\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1343 - accuracy: 0.9641 - val_loss: 1.0821 - val_accuracy: 0.7826\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1339 - accuracy: 0.9646 - val_loss: 1.1066 - val_accuracy: 0.7783\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1314 - accuracy: 0.9652 - val_loss: 1.1056 - val_accuracy: 0.7815\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1278 - accuracy: 0.9658 - val_loss: 1.1280 - val_accuracy: 0.7802\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1253 - accuracy: 0.9670 - val_loss: 1.1286 - val_accuracy: 0.7800\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1254 - accuracy: 0.9668 - val_loss: 1.1364 - val_accuracy: 0.7799\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1227 - accuracy: 0.9676 - val_loss: 1.1429 - val_accuracy: 0.7792\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 38s 1s/step - loss: 0.1214 - accuracy: 0.9675 - val_loss: 1.1477 - val_accuracy: 0.7800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92b8cfa828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2uFKYKZVgVz"
      },
      "source": [
        "model.save('trained_model.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEYC65TCmO_n"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\r\n",
        "\r\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\r\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\r\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\r\n",
        "decoder_states = [state_h, state_c]\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "decoder_model = Model(\r\n",
        "    [decoder_inputs] + decoder_states_inputs,\r\n",
        "    [decoder_outputs] + decoder_states)\r\n",
        "\r\n",
        "reverse_input_char_index = dict(\r\n",
        "    (i, char) for char, i in input_token_index.items())\r\n",
        "reverse_target_char_index = dict(\r\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SwDtX4RmRq0"
      },
      "source": [
        "def decode_sequence(input_seq):\r\n",
        "    states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\r\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\r\n",
        "\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = ''\r\n",
        "    while not stop_condition:\r\n",
        "        output_tokens, h, c = decoder_model.predict(\r\n",
        "            [target_seq] + states_value)\r\n",
        "\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\r\n",
        "        decoded_sentence += sampled_char\r\n",
        "\r\n",
        "        if (sampled_char == '\\n' or\r\n",
        "           len(decoded_sentence) > max_decoder_seq_len):\r\n",
        "            stop_condition = True\r\n",
        "\r\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\r\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\r\n",
        "\r\n",
        "        states_value = [h, c]\r\n",
        "\r\n",
        "    return decoded_sentence\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZeNJ0P5mVhm",
        "outputId": "002732a4-8918-431a-e55c-67f7ef334ca0"
      },
      "source": [
        "for seq_index in range(20):\r\n",
        "    \r\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\r\n",
        "    decoded_sentence = decode_sequence(input_seq)\r\n",
        "    print('-')\r\n",
        "    print(input_texts[seq_index])\r\n",
        "    print(decoded_sentence)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Help!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
            "\n",
            "-\n",
            "Jump.\n",
            "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
            "\n",
            "-\n",
            "Jump.\n",
            "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
            "\n",
            "-\n",
            "Jump.\n",
            "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
            "\n",
            "-\n",
            "Hello!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हैं।\n",
            "\n",
            "-\n",
            "Hello!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हैं।\n",
            "\n",
            "-\n",
            "Cheers!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
            "\n",
            "-\n",
            "Cheers!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
            "\n",
            "-\n",
            "Got it?\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "I'm OK.\n",
            "मैंने उसे बहुत जाने को हैं।\n",
            "\n",
            "-\n",
            "Awesome!\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Come in.\n",
            "मेरी बात ने अभी अक्री पीछी नीीजिए।\n",
            "\n",
            "-\n",
            "Get out!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
            "\n",
            "-\n",
            "Go away!\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Goodbye!\n",
            "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
            "\n",
            "-\n",
            "Perfect!\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Perfect!\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Welcome.\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Welcome.\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n",
            "-\n",
            "Have fun.\n",
            "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0onnyUmY_6"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}
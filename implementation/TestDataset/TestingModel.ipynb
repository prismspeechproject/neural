{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestingModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvB1PAv3RiRg"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding\n",
        "from keras.models import Model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from keras.models import load_model\n",
        "from sklearn.utils import shuffle\n",
        "import unicodedata\n",
        "import re\n",
        "punctuations = set(string.punctuation)\n",
        "\n",
        "digits_rm = str.maketrans('', '', string.digits)\n",
        "not_punc = \".?!,|\"\n",
        "\n",
        "for c in not_punc:\n",
        "      punctuations.remove(c)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHpu_r6SGGG"
      },
      "source": [
        "def create_dataset(url, n=25000, random_state=42):\n",
        "  df = pd.read_csv(url , encoding='utf-8')\n",
        "  df = df[df.columns[0:2]]\n",
        "  df = df[~pd.isnull(df['English'])]\n",
        "  df.drop_duplicates(inplace=True)\n",
        "  df = df.sample(n=25000, random_state=42)\n",
        "  # Calculate number of words in each line of 2 columns\n",
        "  df['len_eng_words'] = df['English'].apply(lambda e: len(str(e).split(\" \")))\n",
        "  df['len_hin_words'] = df['Hindi'].apply(lambda h: len(str(h).split(\" \")))\n",
        "  df = df[df['len_eng_words']<=20]\n",
        "  df = df[df['len_hin_words']<=20]\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-APCa11ScO3E"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocessing_data_hin(w):\n",
        "    w = unicode_to_ascii(str(w).lower().strip())\n",
        "    w = re.sub(r\"[\\(\\[].*?[\\)\\]]\", ' ', w)\n",
        "    w = re.sub(r\"([.?!,])\", r' \\1 ', w)\n",
        "    w = re.sub(r'[\"“”‘]', \" \", w)\n",
        "    w = re.sub(r'[0-9]', \" \", w)\n",
        "    \n",
        "    w = w.strip()\n",
        "\n",
        "    #w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "def preprocessing_data_eng(w):\n",
        "    w = unicode_to_ascii(str(w).lower().strip())\n",
        "    w = re.sub(r\"[\\(\\[].*?[\\)\\]]\", '', w)\n",
        "    w = re.sub(r\"([.?!,])\", r' \\1 ', w)\n",
        "    w = re.sub(r'[\"]', \" \", w)\n",
        "    w = re.sub(r'[^a-zA-Z?.!,]+', \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    return w"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytHCv2k1Uu5E"
      },
      "source": [
        "def customize_dataset(df):\n",
        "    df['Hindi'] = df['Hindi'].apply(lambda h : preprocessing_data_hin(h))\n",
        "    df['English'] = df['English'].apply(lambda e : preprocessing_data_eng(e))\n",
        "    df['Hindi'] = df['Hindi'].apply(lambda h: ''.join(c for c in h if c not in punctuations))\n",
        "    df['English'] = df['English'].apply(lambda e: ''.join(c for c in e if c not in punctuations))\n",
        "    df['English']=df['English'].apply(lambda e: e.translate(digits_rm))\n",
        "    df['Hindi']=df['Hindi'].apply(lambda h: h.translate(digits_rm))\n",
        "    df['Hindi']=df['Hindi'].apply(lambda h: re.sub(\"[a-z२३०८१५७९४६]\", '', h))\n",
        "    df['English'] = df['English'].apply(lambda e : '<start> ' + e + ' <end>')\n",
        "    df['Hindi'] = df['Hindi'].apply(lambda h : '<start> ' + h + ' <end>')\n",
        "\n",
        "    return df['English'], df['Hindi']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpPTOmtSIfZ"
      },
      "source": [
        "def tokenizing(sen):\n",
        "    words = []\n",
        "    for s in sen:\n",
        "        for w in s.split():\n",
        "            if w not in words:\n",
        "                words.append(w)\n",
        "    return words"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ad12m00aV_"
      },
      "source": [
        "def load_dataset():\n",
        "    df = create_dataset('https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv')\n",
        "\n",
        "    input_lang, target_lang = customize_dataset(df)\n",
        "\n",
        "    eng_words = sorted(tokenizing(input_lang))\n",
        "    hin_words = sorted(tokenizing(target_lang))\n",
        "\n",
        "    return input_lang, target_lang, eng_words, hin_words, df"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfx6cz3a1UTO",
        "outputId": "a11185af-a7c3-4ccd-fff1-4e4174ec1052"
      },
      "source": [
        "input_lang, target_lang, eng_words, hin_words, df = load_dataset()\n",
        "\n",
        "num_encoder_words, num_decoder_words, max_input_sen_len, max_target_sen_len = len(eng_words) + 1, len(hin_words) + 1, max(df['len_eng_words']), max(df['len_hin_words'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC2NpRB31VJ1"
      },
      "source": [
        "input_dict_token = dict([(word, i+1) for i, word in enumerate(eng_words)])\n",
        "target_dict_token = dict([(word, i+1) for i, word in enumerate(hin_words)])\n",
        "reverse_input_dict_token = dict([(i, word) for i, word in enumerate(eng_words)])\n",
        "reverse_target_dict_token = dict([(i, word) for i, word in enumerate(hin_words)])\n",
        "df = shuffle(df)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-v92Xez1YJX",
        "outputId": "2af0de42-e880-4449-bf7b-526ba2d6ea22"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(input_lang, target_lang, test_size=0.2 , random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13349,), (3338,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17wVkWau1axr"
      },
      "source": [
        "def generate_batch(X, Y, batch_size=1):\n",
        "\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_input_sen_len), dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_target_sen_len), dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_target_sen_len, num_decoder_words), dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j + batch_size], Y[j: j+batch_size])):\n",
        "                for t, w in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_dict_token[w]\n",
        "                for t, w in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_dict_token[w]\n",
        "                    if t > 0:\n",
        "                        decoder_target_data[i, t-1, target_dict_token[w]] = 1\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaIIftsOeeMX"
      },
      "source": [
        "\n",
        "latent_dim = 300\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_words, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m3kgsYaefbo"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_words, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_words, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDUNd0VQh5e5"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV0jZMGb1c6N"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_dict_token['<start>']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_dict_token[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '<end>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSIY3X-K5qYM"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/Colab/CopyUntitled4/nmt_weights22Ep100.h5')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4pnCUh86qdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd95d239-8aa0-4671-fd7e-f77f482f2142"
      },
      "source": [
        "model.summary"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <keras.engine.functional.Functional object at 0x7f61a1ed3fd0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo8bZ9eOXLG_"
      },
      "source": [
        "wordLen3 = pd.read_csv('https://raw.githubusercontent.com/prismspeechproject/neural/colab-engines/implementation/TestDataset/WordLen3.csv')\n",
        "wordLen3 = shuffle(wordLen3)\n",
        "wordLen3X , wordLen3Y = wordLen3['English'], wordLen3['Hindi']"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSg7a3WYPm2I"
      },
      "source": [
        "test_gen = generate_batch(wordLen3X, wordLen3Y, batch_size=1)\n",
        "k =-1"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psw1IpbUc2Kj",
        "outputId": "fce91bc1-4b44-4894-f6e0-a97d615dabd3"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(test_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: <start> it s less risky <end>\n",
            "Actual Hindi Translation: > जोखिम कम हो जाता ह <\n",
            "Predicted Hindi Translation:  अनतरराषटरीय पठना पठना आभासी दरग भोलापन बचच। विशदध\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuImDsZSc3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4871dedb-730f-4b6c-fde0-35cc9772bdfb"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(test_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: <start> everything is everything <end>\n",
            "Actual Hindi Translation: > सबकछ ही सबकछ ह <\n",
            "Predicted Hindi Translation:  फरनीचर डिवीजनलखडपीठसरवोचच खररीदी फलाप भावभगिमाय भ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aEzOGl8up03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980b2796-4a6c-4e4d-e867-974db81767d2"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(test_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: <start> of human happiness <end>\n",
            "Actual Hindi Translation: > मानवीय सख का | <\n",
            "Predicted Hindi Translation:  ईकॉमरस मआ बढकर नाडी नाडी तीरथो पीज असफलता इकार \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YkO2_GButCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f67e809-7be1-4263-a3bc-c9d973250b59"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(test_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: <start> mosque of tajmahal <end>\n",
            "Actual Hindi Translation: > ताजमहल की मसजिद <\n",
            "Predicted Hindi Translation:  शदधीकरण परसतति टयमर पीना खणड उसतादी चिपकाई। उपलबध क\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv3myr2V0CiK"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v880ei58uyUv",
        "outputId": "c5c56fe3-b1f1-4aa4-cccf-41ea7bd07754"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.000000\n",
            "BLEU-2: 0.000000\n",
            "BLEU-3: 0.000000\n",
            "BLEU-4: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0pEzs0Bz_5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f9712b-57a1-47db-b93f-0ee2ba1016d0"
      },
      "source": [
        "print('Individual 1-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(1, 0, 0, 0)))\n",
        "print('Individual 2-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 1, 0, 0)))\n",
        "print('Individual 3-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 0, 0, 1)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual 1-gram: 0.000000\n",
            "Individual 2-gram: 0.000000\n",
            "Individual 3-gram: 0.000000\n",
            "Individual 4-gram: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuoSc_d03RZN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
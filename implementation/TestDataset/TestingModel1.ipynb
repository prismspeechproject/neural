{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestingModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZbe27BJQ94u",
        "outputId": "ab1a3bc0-b4cf-42a2-eeee-41a08003a12b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "keras.__version__, tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.5.0', '2.5.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvB1PAv3RiRg"
      },
      "source": [
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import LSTM, Dense, Input, Embedding\n",
        "# from tensorflow.keras.models import Model\n",
        "# import os\n",
        "# os.system('wget https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/preprocessdata.py')\n",
        "# import preprocessdata as pe        ## It is builted module\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import string\n",
        "# from keras.models import load_model\n",
        "# import tensorflow as tf\n",
        "# from sklearn.utils import shuffle\n",
        "# import unicodedata\n",
        "# import re\n",
        "# punctuations = set(string.punctuation)\n",
        "\n",
        "# digits_rm = str.maketrans('', '', string.digits)\n",
        "# not_punc = \".?!,|\"\n",
        "\n",
        "# for c in not_punc:\n",
        "#       punctuations.remove(c)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXKdKVApTTss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78799dc-1639-472b-f90f-aa3f4826b4a1"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHpu_r6SGGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2690e45b-b69f-485a-876a-4a04699cc43f"
      },
      "source": [
        "# lines=pd.read_csv(\"/content/drive/MyDrive/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
        "url = 'https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv'\n",
        "lines=pd.read_csv(url, encoding='utf-8')\n",
        "lines= lines[lines.columns[0:2]]\n",
        "lines=lines[~pd.isnull(lines['English'])]\n",
        "lines=lines[~pd.isnull(lines['Hindi'])]\n",
        "lines=lines.sample(n=25000,random_state=42)\n",
        "lines.drop_duplicates(inplace=True)\n",
        "lines.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24677, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-APCa11ScO3E"
      },
      "source": [
        "lines['English']=lines['English'].apply(lambda x: x.lower())\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.lower())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytHCv2k1Uu5E"
      },
      "source": [
        "\n",
        "lines['English']=lines['English'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpPTOmtSIfZ"
      },
      "source": [
        "exclude = set(string.punctuation) \n",
        "lines['English']=lines['English'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ad12m00aV_"
      },
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['English']=lines['English'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['Hindi'] = lines['Hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "lines['English']=lines['English'].apply(lambda x: x.strip())\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.strip())\n",
        "lines['English']=lines['English'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfx6cz3a1UTO"
      },
      "source": [
        "# # input_lang, target_lang, eng_words, hin_words, df = load_dataset()\n",
        "\n",
        "# # num_encoder_words, num_decoder_words, max_input_sen_len, max_target_sen_len = len(eng_words) + 1, len(hin_words) + 1, max(df['len_eng_words']), max(df['len_hin_words'])\n",
        "# '''\n",
        "#         Here I loaded imported prepocessdata.load_dataset\n",
        "# '''\n",
        "\n",
        "\n",
        "# url = 'https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv'\n",
        "# input_dict_token, target_dict_token, reverse_input_dict_token, reverse_target_dict_token, df = pe.load_dataset(url)\n",
        "# num_encoder_words  = len(input_dict_token) + 1\n",
        "# num_decoder_words = len(target_dict_token) + 1\n",
        "# max_input_sen_len = max(df['len_eng_words'])\n",
        "# max_target_sen_len = max(df['len_hin_words'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC2NpRB31VJ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "61c5e2f4-6605-43db-ea23-35dee8291561"
      },
      "source": [
        "\n",
        "lines['Hindi'] = lines['Hindi'].apply(lambda x : 'START_ '+ x + ' _END')\n",
        "lines.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64063</th>\n",
              "      <td>the old man s ghost is obsession with past which rides on the shoulders of present subjecting the welfare of the living to a vain glorification of national culture and an unreasoning dread of change</td>\n",
              "      <td>START_ इस बूढ़े आदमी का भूत और कुछ नहीं अतीत के प्रति उसका ऐसा मोह है जो वर्तमान के कंधे पर सवार है किसी के कल्याण का दमन करते हुए राष्ट्रीय संस्कृति और अकारण परिवर्तन की आशंका से उसे अन्यथा गौरवान्वित करता है _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125354</th>\n",
              "      <td>as a result of authenticity</td>\n",
              "      <td>START_ सच्चा होने की वजह से _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5417</th>\n",
              "      <td>special session of lokshabha lower house there is description of it in article but it was established with the th amendment in if at least one tenth of the members of lokshabha brought an proposal in which it is stated to continue national emergency then within days of notice period the session will be called</td>\n",
              "      <td>START_ लोकसभा का विशेष सत्र अनु मे इसका वर्णन है किंतु इसे वें संशोधन से स्थापित किया गया है यदि लोकसभा के कम से कम सद्स्य एक प्रस्ताव लाते है जिसमे राष्ट्रीय आपातकाल को जारी न रखने की बात कही गयी है तो नोटिस देने के दिन के भीतर सत्र बुलाया जायेगा _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104883</th>\n",
              "      <td>kabir das was one of the greatest poets in indian worship poetry tradition</td>\n",
              "      <td>START_ कबीरदास भारत के भक्ति काव्य परंपरा के महानतम कवियों में से एक थे। _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40881</th>\n",
              "      <td>in india there is high court whose rights and responsibility is limited as compared to supreme court</td>\n",
              "      <td>START_ भारत में उच्च न्यायालय हैं जिनके अधिकार और उत्तरदायित्व सर्वोच्च न्यायालय की अपेक्षा सीमित हैं। _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                       English                                                                                                                                                                                                                                                         Hindi\n",
              "64063   the old man s ghost is obsession with past which rides on the shoulders of present subjecting the welfare of the living to a vain glorification of national culture and an unreasoning dread of change                                                                                                                  START_ इस बूढ़े आदमी का भूत और कुछ नहीं अतीत के प्रति उसका ऐसा मोह है जो वर्तमान के कंधे पर सवार है किसी के कल्याण का दमन करते हुए राष्ट्रीय संस्कृति और अकारण परिवर्तन की आशंका से उसे अन्यथा गौरवान्वित करता है _END                                      \n",
              "125354  as a result of authenticity                                                                                                                                                                                                                                                                                             START_ सच्चा होने की वजह से _END                                                                                                                                                                                                                            \n",
              "5417    special session of lokshabha lower house there is description of it in article but it was established with the th amendment in if at least one tenth of the members of lokshabha brought an proposal in which it is stated to continue national emergency then within days of notice period the session will be called  START_ लोकसभा का विशेष सत्र अनु मे इसका वर्णन है किंतु इसे वें संशोधन से स्थापित किया गया है यदि लोकसभा के कम से कम सद्स्य एक प्रस्ताव लाते है जिसमे राष्ट्रीय आपातकाल को जारी न रखने की बात कही गयी है तो नोटिस देने के दिन के भीतर सत्र बुलाया जायेगा _END\n",
              "104883  kabir das was one of the greatest poets in indian worship poetry tradition                                                                                                                                                                                                                                              START_ कबीरदास भारत के भक्ति काव्य परंपरा के महानतम कवियों में से एक थे। _END                                                                                                                                                                               \n",
              "40881   in india there is high court whose rights and responsibility is limited as compared to supreme court                                                                                                                                                                                                                    START_ भारत में उच्च न्यायालय हैं जिनके अधिकार और उत्तरदायित्व सर्वोच्च न्यायालय की अपेक्षा सीमित हैं। _END                                                                                                                                                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-v92Xez1YJX"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(df['English'], df['Hindi'], test_size=0.2 , random_state=42)\n",
        "# X_train.shape, X_test.shape"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BP65WseSizB"
      },
      "source": [
        "\n",
        "all_eng_words=set()\n",
        "for eng in lines['English']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['Hindi']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrwSrTEuSm1o"
      },
      "source": [
        "lines['length_eng_sentence']=lines['English'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['Hindi'].apply(lambda x:len(x.split(\" \")))\n",
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]\n",
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG0V4rPUSwqp",
        "outputId": "5ccb43b7-eb1b-4e8d-b5b3-b16359e1c188"
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30764, 37047)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvN6Y-4TS0wU"
      },
      "source": [
        "num_decoder_tokens += 1 \n",
        "num_encoder_tokens = num_encoder_tokens + 1 "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHNrWD-fS1ft"
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oOC7yLKS3qh"
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LM_dGySFS56F",
        "outputId": "055a3836-f8d4-4cd4-c803-603644cc902a"
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44854</th>\n",
              "      <td>news about nepal</td>\n",
              "      <td>START_ नेपाल की खबर _END</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5238</th>\n",
              "      <td>evolution works that way</td>\n",
              "      <td>START_ क्रमिक विकास ऐसे काम करता है _END</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36167</th>\n",
              "      <td>in india among people birth rate and of them are under age</td>\n",
              "      <td>START_ भारत की जनसंख्या में जन्मों के साथ बढती जनसंख्या के आधे लोग वर्ष से कम आयु के हैं। _END</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8961</th>\n",
              "      <td>this is called the muslim agricultural revolution</td>\n",
              "      <td>START_ यह मुस्लिम कृषि क्रांति कहलाती है। _END</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96674</th>\n",
              "      <td>this also is built with marble and red sandstone</td>\n",
              "      <td>START_ यह भी संगमर्मर एवं लाल बलुआ पत्थर से निर्मित है। _END</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45576</th>\n",
              "      <td>it was printed in monterey i checked and the story began</td>\n",
              "      <td>START_ वह मोंटेरे में छपी थी मैंने जांच करी थी और कहानी ऐसे शुरू हुई थी _END</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23297</th>\n",
              "      <td>constitution has three parts</td>\n",
              "      <td>START_ संविधान के तीन भाग _END</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121643</th>\n",
              "      <td>“”gunmain nirgun nirgun main gun baat chaadi kyun bahinse“”</td>\n",
              "      <td>START_ गुनमैं निरगुन निरगुनमैं गुन बाट छांड़ि क्यूं बहिसे _END</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115427</th>\n",
              "      <td>to leverage our common humanity</td>\n",
              "      <td>START_ अपनी साझा मानवता का फ़ायदा उठाने के लिये। _END</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58571</th>\n",
              "      <td>he was not entitled to entertain those cases where the claim was in dispute</td>\n",
              "      <td>START_ वह उन मामलों को हाथ में नहीं ले सकता था जिनमें दावा विवादग्रस्त हो _END</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            English                                                                                           Hindi  length_eng_sentence  length_hin_sentence\n",
              "44854   news about nepal                                                             START_ नेपाल की खबर _END                                                                        3                    5                  \n",
              "5238    evolution works that way                                                     START_ क्रमिक विकास ऐसे काम करता है _END                                                        4                    8                  \n",
              "36167   in india among people birth rate and of them are under age                   START_ भारत की जनसंख्या में जन्मों के साथ बढती जनसंख्या के आधे लोग वर्ष से कम आयु के हैं। _END  12                   20                 \n",
              "8961    this is called the muslim agricultural revolution                            START_ यह मुस्लिम कृषि क्रांति कहलाती है। _END                                                  7                    8                  \n",
              "96674   this also is built with marble and red sandstone                             START_ यह भी संगमर्मर एवं लाल बलुआ पत्थर से निर्मित है। _END                                    9                    12                 \n",
              "45576   it was printed in monterey i checked and the story began                     START_ वह मोंटेरे में छपी थी मैंने जांच करी थी और कहानी ऐसे शुरू हुई थी _END                    11                   17                 \n",
              "23297   constitution has three parts                                                 START_ संविधान के तीन भाग _END                                                                  4                    6                  \n",
              "121643  “”gunmain nirgun nirgun main gun baat chaadi kyun bahinse“”                  START_ गुनमैं निरगुन निरगुनमैं गुन बाट छांड़ि क्यूं बहिसे _END                                  9                    10                 \n",
              "115427  to leverage our common humanity                                              START_ अपनी साझा मानवता का फ़ायदा उठाने के लिये। _END                                           5                    10                 \n",
              "58571   he was not entitled to entertain those cases where the claim was in dispute  START_ वह उन मामलों को हाथ में नहीं ले सकता था जिनमें दावा विवादग्रस्त हो _END                  14                   16                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pza9PN0ES_C-",
        "outputId": "58263b74-64e6-4e6f-9138-53d37cd5a251"
      },
      "source": [
        "X, y = lines['English'], lines['Hindi']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13104,), (3276,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17wVkWau1axr"
      },
      "source": [
        "# def generate_batch(X, Y, batch_size=1):\n",
        "\n",
        "#     while True:\n",
        "#         for j in range(0, len(X), batch_size):\n",
        "#             encoder_input_data = np.zeros((batch_size, max_input_sen_len), dtype='float32')\n",
        "#             decoder_input_data = np.zeros((batch_size, max_target_sen_len), dtype='float32')\n",
        "#             decoder_target_data = np.zeros((batch_size, max_target_sen_len, num_decoder_words), dtype='float32')\n",
        "#             for i, (input_text, target_text) in enumerate(zip(X[j:j + batch_size], Y[j: j+batch_size])):\n",
        "#                 for t, w in enumerate(input_text.split()):\n",
        "#                     encoder_input_data[i, t] = input_dict_token[w]\n",
        "#                 for t, w in enumerate(target_text.split()):\n",
        "#                     if t<len(target_text.split())-1:\n",
        "#                         decoder_input_data[i, t] = target_dict_token[w]\n",
        "#                     if t > 0:\n",
        "#                         decoder_target_data[i, t-1, target_dict_token[w]] = 1\n",
        "#             yield([encoder_input_data, decoder_input_data], decoder_target_data)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09VXXL5FTEyH"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaIIftsOeeMX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "1b7fe938-619c-4db3-a732-6a966968f752"
      },
      "source": [
        "latent_dim=300\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_words, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-111b9e661bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menc_emb\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_encoder_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoder_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_encoder_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m3kgsYaefbo"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_words, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_words, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fopsIasJwfS"
      },
      "source": [
        "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "# model.load_weights('/content/drive/MyDrive/Colab/ResultPNA2Weights.h5')\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab/ResultPNA2.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brAAh0U-TwNa",
        "outputId": "f5058858-6018-41ff-c100-52f0e792e99c"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    9249000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    11230500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 37435)  11267935    lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 33,189,835\n",
            "Trainable params: 33,189,835\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDUNd0VQh5e5"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVv5WY2QGoYM",
        "outputId": "a9c6f7b2-3f13-4fce-c33a-d3dc3bc080d3"
      },
      "source": [
        "# decoder_model.load_weights('/content/drive/MyDrive/Colab/ResultPNA2DecoderModelW.h5')\n",
        "# encoder_model.load_weights('/content/drive/MyDrive/Colab/ResultPNA2EncoderModelW.h5')\n",
        "from keras.models import load_model\n",
        "\n",
        "encoder_model = load_model('/content/drive/MyDrive/Colab/ResultPNA2EncoderModel.h5')\n",
        "decoder_model = load_model('/content/drive/MyDrive/Colab/ResultPNA2DecoderModel.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV0jZMGb1c6N"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSIY3X-K5qYM"
      },
      "source": [
        "# model = load_model('/content/drive/MyDrive/Colab/CopyUntitled4/nmt_model_check.h5')\n",
        "#from keras.models import load_w\n",
        "# decoder_model.load_weights('/content/drive/MyDrive/Colab/copyofnmt_model_check.h5')\n",
        "model = load_model('/content/drive/MyDrive/Colab/CopyUntitled4/nmt_weights22Ep100.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4pnCUh86qdW"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo8bZ9eOXLG_"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "wordLen3 = pd.read_csv('https://raw.githubusercontent.com/prismspeechproject/neural/colab-engines/implementation/TestDataset/WordLen4.csv')\n",
        "wordLen3 = shuffle(wordLen3)\n",
        "wordLen3X , wordLen3Y = wordLen3['English'], wordLen3['Hindi']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSg7a3WYPm2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "765dac6c-8e8d-4c80-b731-5a83a1a7c5e9"
      },
      "source": [
        "test_gen = generate_batch(wordLen3X, wordLen3Y, batch_size=1)\n",
        "k =-1\n",
        "#model.load_weights(checkpoint_dir)\n",
        "#checkpoint.restore(model , tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-56cedae76cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordLen3X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordLen3Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.load_weights(checkpoint_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#checkpoint.restore(model , tf.train.latest_checkpoint(checkpoint_dir))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgNjUHyLZRfw"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psw1IpbUc2Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba54c59-9652-4899-952a-66aa789b277b"
      },
      "source": [
        "# k+=1\n",
        "# (input_seq, actual_output), _ = next(train_gen)\n",
        "# decoded_sentence = decode_sequence(input_seq)\n",
        "# print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "# print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "# print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: the best chooses me ”\n",
            "Actual Hindi Translation:  सर्वोत्तम मुझे चुनता है \n",
            "Predicted Hindi Translation:  ओल्डमैन्स औष्घाणीशाठीऔण् धर्माप्रचारकों आडू किस\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuImDsZSc3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bf8e34-3a15-468b-b415-9c07ab8fb4a8"
      },
      "source": [
        "# k+=1\n",
        "# (input_seq, actual_output), _ = next(train_gen)\n",
        "# decoded_sentence = decode_sequence(input_seq)\n",
        "# print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "# print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "# print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: at my normal ”\n",
            "Actual Hindi Translation:  मेरी आम ” की लम्बाई से \n",
            "Predicted Hindi Translation:  सहज कृष्णपुरम संशोधनोंस्थानापन्न क़्यों राजशाह\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aEzOGl8up03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc5fc3f-4181-4798-995a-1ffcbecaff9c"
      },
      "source": [
        "# k+=1\n",
        "# (input_seq, actual_output), _ = next(test_gen)\n",
        "# decoded_sentence = decode_sequence(input_seq)\n",
        "# print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "# print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "# print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: and my body had clearly changed and matt mussolina\n",
            "Actual Hindi Translation:  और ज़ाहिर है कि मेरा शरीर बदल रहा था और मैट मुसोलिना \n",
            "Predicted Hindi Translation:  इष्टतम तारो गई। ज़मीन क़्यों प्राथमिकताएं ग्रीष्मक\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YkO2_GButCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b81bdb-66c8-4401-ba17-10122d7e9b69"
      },
      "source": [
        "# k+=1\n",
        "# (input_seq, actual_output), _ = next(test_gen)\n",
        "# decoded_sentence = decode_sequence(input_seq)\n",
        "# print('Input English sentence:', wordLen3X[k:k+1].values[0])\n",
        "# print('Actual Hindi Translation:', wordLen3Y[k:k+1].values[0][6:-4])\n",
        "# print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "\n",
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: tools to translate hindi in firefox\n",
            "Actual Hindi Translation:  फायरफॉक्स में हिन्दी टाइपिंग के औजार \n",
            "Predicted Hindi Translation:  इलियास कारखाना मौर्यों मजेदार कॉर्नर हाइड्रोzzफि\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv3myr2V0CiK"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v880ei58uyUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8949d478-982f-4a25-c5dc-59006bd10525"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.000000\n",
            "BLEU-2: 0.000000\n",
            "BLEU-3: 0.000000\n",
            "BLEU-4: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0pEzs0Bz_5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6742d4-616e-462e-ab54-e14cf3e3394e"
      },
      "source": [
        "print('Individual 1-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(1, 0, 0, 0)))\n",
        "print('Individual 2-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 1, 0, 0)))\n",
        "print('Individual 3-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % corpus_bleu([actual_output], [decoded_sentence], weights=(0, 0, 0, 1)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual 1-gram: 0.000000\n",
            "Individual 2-gram: 0.000000\n",
            "Individual 3-gram: 0.000000\n",
            "Individual 4-gram: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkcbUCmodLua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06acecd-1d06-4e72-f4ce-fabcce3ded9d"
      },
      "source": [
        "encoder_model.get_weights()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.03819279, -0.0322782 , -0.03939082, ...,  0.00416565,\n",
              "          0.02199462, -0.04040111],\n",
              "        [-0.24462663,  0.07550556, -0.02188983, ..., -0.05438171,\n",
              "         -0.05992344, -0.14644411],\n",
              "        [-0.02854334,  0.01091386,  0.06664548, ..., -0.00438381,\n",
              "          0.09545403, -0.08324859],\n",
              "        ...,\n",
              "        [-0.01087225,  0.05336149,  0.09070357, ..., -0.01562318,\n",
              "         -0.02250707, -0.18338294],\n",
              "        [-0.1053583 ,  0.04338017, -0.00409952, ...,  0.06310016,\n",
              "          0.02308963,  0.11768317],\n",
              "        [-0.00641337, -0.00235736, -0.00291197, ...,  0.06093942,\n",
              "         -0.07201329, -0.03548596]], dtype=float32),\n",
              " array([[-2.3507608e-01, -5.9964079e-02,  3.3216095e-01, ...,\n",
              "          1.4458965e-01,  2.2424659e-01, -2.0234863e-01],\n",
              "        [ 1.1874749e-01, -1.2757336e-01,  2.1041945e-02, ...,\n",
              "          2.0338273e-05, -2.1128204e-01,  2.9830477e-01],\n",
              "        [-7.7597684e-01, -2.7464086e-01, -8.0915622e-02, ...,\n",
              "         -2.5459874e-01, -1.7398483e-01, -1.4230114e-01],\n",
              "        ...,\n",
              "        [-3.8531911e-01, -1.6687453e-02, -1.6208571e-01, ...,\n",
              "          1.5333110e-01, -1.4224118e-02, -2.2187987e-02],\n",
              "        [ 5.7290369e-01,  2.6169011e-01,  2.5944138e-01, ...,\n",
              "          4.5420635e-03,  2.5646937e-01,  2.6176408e-01],\n",
              "        [-5.6411684e-01, -4.3227646e-02,  1.1736551e-02, ...,\n",
              "         -2.4091479e-01,  5.0451738e-01,  2.2263160e-01]], dtype=float32),\n",
              " array([[-0.5140193 ,  0.12388367, -0.08995879, ...,  0.24168658,\n",
              "         -0.07153021, -0.28896716],\n",
              "        [-0.00258562,  0.02860031, -0.03270608, ...,  0.07207741,\n",
              "          0.05939965,  0.26406434],\n",
              "        [ 0.02908781, -0.05320995, -0.06270514, ...,  0.1390821 ,\n",
              "         -0.00512369,  0.02164891],\n",
              "        ...,\n",
              "        [ 0.05001071,  0.06062172,  0.18688244, ..., -0.06610586,\n",
              "          0.10754993,  0.07867067],\n",
              "        [-0.06565181, -0.13549685, -0.1377466 , ...,  0.02419269,\n",
              "          0.07246044,  0.10446427],\n",
              "        [-0.18107332, -0.06860894,  0.15981804, ...,  0.01237164,\n",
              "          0.06070758,  0.01696055]], dtype=float32),\n",
              " array([ 0.3225542 ,  0.22125079,  0.35495254, ..., -0.0304928 ,\n",
              "         0.07943121,  0.5893062 ], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp7YAF7p-rlK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
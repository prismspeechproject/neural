{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "71KIDaovPASn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 2048\n",
    "num_samples = 127606\n",
    "filename = 'English_hindi.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sgUhidzEUZdA"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-839603c76eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtarget_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_characters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "# vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = []\n",
    "target_characters = []\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "input_texts = df['English'].values.tolist()\n",
    "target_texts = df['Hindi'].values.tolist()\n",
    "\n",
    "for i in range(len(target_texts)):\n",
    "    target_texts[i] = '\\t' + target_texts[i] + '\\n'\n",
    "    for char in input_texts[i]:\n",
    "        if char not in input_characters:\n",
    "            input_characters.append(char)\n",
    "    for char in target_texts[i]:\n",
    "        if char not in target_characters:\n",
    "            target_characters.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2SzPIOK4UnMM"
   },
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_len = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_len = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4i-vFE-Uux5",
    "outputId": "5402f339-7a17-4c31-ec86-fbee4a093bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i/p characters : 70\n",
      "targert characters : 87\n",
      "encoder characters : 70\n",
      "decoder characters : 87\n",
      "max encoder : 107\n",
      "max decoder : 123\n"
     ]
    }
   ],
   "source": [
    "print('i/p characters : {}'.format(len(input_characters)))\n",
    "print('targert characters : {}'.format(len(target_characters)))\n",
    "print('encoder characters : {}'.format(num_encoder_tokens))\n",
    "print('decoder characters : {}'.format(num_decoder_tokens))\n",
    "print('max encoder : {}'.format(max_encoder_seq_len))\n",
    "print('max decoder : {}'.format(max_decoder_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9I4qgaOpUz8t",
    "outputId": "125ad5e8-033b-4562-ed7a-2feef17c31f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '$': 3, \"'\": 4, ',': 5, '-': 6, '.': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17, ':': 18, '?': 19, 'A': 20, 'B': 21, 'C': 22, 'D': 23, 'E': 24, 'F': 25, 'G': 26, 'H': 27, 'I': 28, 'J': 29, 'K': 30, 'L': 31, 'M': 32, 'N': 33, 'O': 34, 'P': 35, 'Q': 36, 'R': 37, 'S': 38, 'T': 39, 'U': 40, 'V': 41, 'W': 42, 'Y': 43, 'a': 44, 'b': 45, 'c': 46, 'd': 47, 'e': 48, 'f': 49, 'g': 50, 'h': 51, 'i': 52, 'j': 53, 'k': 54, 'l': 55, 'm': 56, 'n': 57, 'o': 58, 'p': 59, 'q': 60, 'r': 61, 's': 62, 't': 63, 'u': 64, 'v': 65, 'w': 66, 'x': 67, 'y': 68, 'z': 69}\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '5': 10, ':': 11, '?': 12, 'I': 13, '|': 14, 'ँ': 15, 'ं': 16, 'ः': 17, 'अ': 18, 'आ': 19, 'इ': 20, 'ई': 21, 'उ': 22, 'ऊ': 23, 'ऋ': 24, 'ए': 25, 'ऐ': 26, 'ऑ': 27, 'ओ': 28, 'औ': 29, 'क': 30, 'ख': 31, 'ग': 32, 'घ': 33, 'च': 34, 'छ': 35, 'ज': 36, 'झ': 37, 'ञ': 38, 'ट': 39, 'ठ': 40, 'ड': 41, 'ढ': 42, 'ण': 43, 'त': 44, 'थ': 45, 'द': 46, 'ध': 47, 'न': 48, 'प': 49, 'फ': 50, 'ब': 51, 'भ': 52, 'म': 53, 'य': 54, 'र': 55, 'ल': 56, 'व': 57, 'श': 58, 'ष': 59, 'स': 60, 'ह': 61, '़': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॅ': 69, 'े': 70, 'ै': 71, 'ॉ': 72, 'ो': 73, 'ौ': 74, '्': 75, '।': 76, '०': 77, '१': 78, '२': 79, '४': 80, '५': 81, '६': 82, '७': 83, '८': 84, '९': 85, '\\u200d': 86}\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])\n",
    "print(input_token_index)\n",
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wmBpRsSzVD7G"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_len, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DfXHofhPVInE"
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t+1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]] = 1.\n",
    "    decoder_input_data[i,t+1:,target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i,t:,target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ptYGuw0VOtS",
    "outputId": "9176a793-0755-48fc-c453-0835128fff03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 70)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bG-LYA-zVSqA"
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it\n",
    "encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
    "encoder=LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs, state_h, state_c=encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NNhgkKDNVXs-"
   },
   "outputs": [],
   "source": [
    "# Set up decoder , using ` encoder_states` as initial state\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well . we don't use the \n",
    "# return states in the training model , but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense= Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs= decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh4zcfy0VdFT",
    "outputId": "1541bd55-d190-4a0b-e1c2-816009690dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 42s 1s/step - loss: 1.7573 - accuracy: 0.7125 - val_loss: 1.6320 - val_accuracy: 0.6896\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.9785 - accuracy: 0.8071 - val_loss: 1.3610 - val_accuracy: 0.6897\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.8524 - accuracy: 0.8084 - val_loss: 1.9723 - val_accuracy: 0.6892\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.8200 - accuracy: 0.8083 - val_loss: 1.4358 - val_accuracy: 0.6901\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.7650 - accuracy: 0.8122 - val_loss: 1.2542 - val_accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.7256 - accuracy: 0.8195 - val_loss: 1.1655 - val_accuracy: 0.7054\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.6996 - accuracy: 0.8289 - val_loss: 1.1083 - val_accuracy: 0.7206\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.6403 - accuracy: 0.8397 - val_loss: 1.0351 - val_accuracy: 0.7336\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.6007 - accuracy: 0.8463 - val_loss: 0.9987 - val_accuracy: 0.7377\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.5694 - accuracy: 0.8541 - val_loss: 0.9594 - val_accuracy: 0.7482\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.5386 - accuracy: 0.8594 - val_loss: 0.9503 - val_accuracy: 0.7509\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.5276 - accuracy: 0.8611 - val_loss: 0.9108 - val_accuracy: 0.7595\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.5109 - accuracy: 0.8653 - val_loss: 0.9002 - val_accuracy: 0.7600\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.5074 - accuracy: 0.8653 - val_loss: 0.8837 - val_accuracy: 0.7677\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4865 - accuracy: 0.8711 - val_loss: 0.8600 - val_accuracy: 0.7705\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4801 - accuracy: 0.8717 - val_loss: 0.8712 - val_accuracy: 0.7694\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4734 - accuracy: 0.8732 - val_loss: 0.8394 - val_accuracy: 0.7748\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.4656 - accuracy: 0.8742 - val_loss: 0.8294 - val_accuracy: 0.7774\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.4611 - accuracy: 0.8742 - val_loss: 0.8278 - val_accuracy: 0.7770\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.4482 - accuracy: 0.8766 - val_loss: 0.8237 - val_accuracy: 0.7782\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4450 - accuracy: 0.8775 - val_loss: 0.8105 - val_accuracy: 0.7799\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.4323 - accuracy: 0.8804 - val_loss: 0.8049 - val_accuracy: 0.7804\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4287 - accuracy: 0.8812 - val_loss: 0.7950 - val_accuracy: 0.7825\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4183 - accuracy: 0.8832 - val_loss: 0.7925 - val_accuracy: 0.7834\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4108 - accuracy: 0.8848 - val_loss: 0.7768 - val_accuracy: 0.7883\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4129 - accuracy: 0.8842 - val_loss: 0.7839 - val_accuracy: 0.7855\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4058 - accuracy: 0.8863 - val_loss: 0.7780 - val_accuracy: 0.7867\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3977 - accuracy: 0.8886 - val_loss: 0.7652 - val_accuracy: 0.7907\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3883 - accuracy: 0.8910 - val_loss: 0.7634 - val_accuracy: 0.7920\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3894 - accuracy: 0.8904 - val_loss: 0.7735 - val_accuracy: 0.7901\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3816 - accuracy: 0.8930 - val_loss: 0.7578 - val_accuracy: 0.7913\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3729 - accuracy: 0.8951 - val_loss: 0.7622 - val_accuracy: 0.7930\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3660 - accuracy: 0.8968 - val_loss: 0.7609 - val_accuracy: 0.7927\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3625 - accuracy: 0.8978 - val_loss: 0.7612 - val_accuracy: 0.7934\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3591 - accuracy: 0.8986 - val_loss: 0.7570 - val_accuracy: 0.7962\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3536 - accuracy: 0.9000 - val_loss: 0.7604 - val_accuracy: 0.7948\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3428 - accuracy: 0.9033 - val_loss: 0.7629 - val_accuracy: 0.7951\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3353 - accuracy: 0.9052 - val_loss: 0.7627 - val_accuracy: 0.7951\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3329 - accuracy: 0.9058 - val_loss: 0.7533 - val_accuracy: 0.7962\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3301 - accuracy: 0.9070 - val_loss: 0.7525 - val_accuracy: 0.7973\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3276 - accuracy: 0.9071 - val_loss: 0.7544 - val_accuracy: 0.7977\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3246 - accuracy: 0.9078 - val_loss: 0.7597 - val_accuracy: 0.7951\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3219 - accuracy: 0.9087 - val_loss: 0.7717 - val_accuracy: 0.7940\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3084 - accuracy: 0.9127 - val_loss: 0.7783 - val_accuracy: 0.7936\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3052 - accuracy: 0.9137 - val_loss: 0.7767 - val_accuracy: 0.7943\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3012 - accuracy: 0.9145 - val_loss: 0.7717 - val_accuracy: 0.7954\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3000 - accuracy: 0.9160 - val_loss: 0.7696 - val_accuracy: 0.7962\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2872 - accuracy: 0.9194 - val_loss: 0.7807 - val_accuracy: 0.7942\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2832 - accuracy: 0.9198 - val_loss: 0.7917 - val_accuracy: 0.7906\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2803 - accuracy: 0.9209 - val_loss: 0.7995 - val_accuracy: 0.7918\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2784 - accuracy: 0.9214 - val_loss: 0.7807 - val_accuracy: 0.7955\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2710 - accuracy: 0.9241 - val_loss: 0.8033 - val_accuracy: 0.7903\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2706 - accuracy: 0.9241 - val_loss: 0.8111 - val_accuracy: 0.7917\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2617 - accuracy: 0.9266 - val_loss: 0.8067 - val_accuracy: 0.7935\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2569 - accuracy: 0.9277 - val_loss: 0.8250 - val_accuracy: 0.7894\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.2534 - accuracy: 0.9292 - val_loss: 0.8142 - val_accuracy: 0.7924\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2474 - accuracy: 0.9308 - val_loss: 0.8211 - val_accuracy: 0.7912\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2452 - accuracy: 0.9315 - val_loss: 0.8340 - val_accuracy: 0.7900\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2346 - accuracy: 0.9352 - val_loss: 0.8380 - val_accuracy: 0.7901\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2332 - accuracy: 0.9347 - val_loss: 0.8457 - val_accuracy: 0.7891\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2320 - accuracy: 0.9351 - val_loss: 0.8549 - val_accuracy: 0.7884\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2280 - accuracy: 0.9368 - val_loss: 0.8574 - val_accuracy: 0.7875\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2231 - accuracy: 0.9381 - val_loss: 0.8668 - val_accuracy: 0.7864\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2155 - accuracy: 0.9402 - val_loss: 0.8811 - val_accuracy: 0.7870\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2186 - accuracy: 0.9390 - val_loss: 0.8892 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2144 - accuracy: 0.9407 - val_loss: 0.8888 - val_accuracy: 0.7870\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2066 - accuracy: 0.9429 - val_loss: 0.8860 - val_accuracy: 0.7896\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2028 - accuracy: 0.9441 - val_loss: 0.9016 - val_accuracy: 0.7863\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1983 - accuracy: 0.9453 - val_loss: 0.9165 - val_accuracy: 0.7849\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1952 - accuracy: 0.9463 - val_loss: 0.9220 - val_accuracy: 0.7853\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1912 - accuracy: 0.9473 - val_loss: 0.9365 - val_accuracy: 0.7853\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1887 - accuracy: 0.9483 - val_loss: 0.9284 - val_accuracy: 0.7835\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1867 - accuracy: 0.9491 - val_loss: 0.9480 - val_accuracy: 0.7839\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1845 - accuracy: 0.9495 - val_loss: 0.9476 - val_accuracy: 0.7833\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1803 - accuracy: 0.9509 - val_loss: 0.9539 - val_accuracy: 0.7850\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1780 - accuracy: 0.9513 - val_loss: 0.9589 - val_accuracy: 0.7838\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1723 - accuracy: 0.9534 - val_loss: 0.9624 - val_accuracy: 0.7849\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1700 - accuracy: 0.9543 - val_loss: 0.9737 - val_accuracy: 0.7837\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1681 - accuracy: 0.9543 - val_loss: 1.0057 - val_accuracy: 0.7806\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1651 - accuracy: 0.9552 - val_loss: 0.9851 - val_accuracy: 0.7837\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1632 - accuracy: 0.9561 - val_loss: 1.0016 - val_accuracy: 0.7827\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1610 - accuracy: 0.9563 - val_loss: 1.0040 - val_accuracy: 0.7827\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1575 - accuracy: 0.9576 - val_loss: 1.0264 - val_accuracy: 0.7823\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1552 - accuracy: 0.9585 - val_loss: 1.0261 - val_accuracy: 0.7825\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1502 - accuracy: 0.9598 - val_loss: 1.0380 - val_accuracy: 0.7820\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1486 - accuracy: 0.9602 - val_loss: 1.0382 - val_accuracy: 0.7817\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1464 - accuracy: 0.9610 - val_loss: 1.0540 - val_accuracy: 0.7813\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1450 - accuracy: 0.9611 - val_loss: 1.0454 - val_accuracy: 0.7817\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1428 - accuracy: 0.9619 - val_loss: 1.0783 - val_accuracy: 0.7804\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1393 - accuracy: 0.9629 - val_loss: 1.0773 - val_accuracy: 0.7805\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1365 - accuracy: 0.9640 - val_loss: 1.0779 - val_accuracy: 0.7817\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1371 - accuracy: 0.9639 - val_loss: 1.0901 - val_accuracy: 0.7818\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1343 - accuracy: 0.9641 - val_loss: 1.0821 - val_accuracy: 0.7826\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1339 - accuracy: 0.9646 - val_loss: 1.1066 - val_accuracy: 0.7783\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1314 - accuracy: 0.9652 - val_loss: 1.1056 - val_accuracy: 0.7815\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1278 - accuracy: 0.9658 - val_loss: 1.1280 - val_accuracy: 0.7802\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1253 - accuracy: 0.9670 - val_loss: 1.1286 - val_accuracy: 0.7800\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1254 - accuracy: 0.9668 - val_loss: 1.1364 - val_accuracy: 0.7799\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1227 - accuracy: 0.9676 - val_loss: 1.1429 - val_accuracy: 0.7792\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1214 - accuracy: 0.9675 - val_loss: 1.1477 - val_accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92b8cfa828>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model that will turn \n",
    "# `encoder_input_data` and `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size= batch_size, epochs = epochs , \n",
    "           validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N2uFKYKZVgVz"
   },
   "outputs": [],
   "source": [
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FEYC65TCmO_n"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2SwDtX4RmRq0"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZeNJ0P5mVhm",
    "outputId": "2d7c65d8-ca10-4f10-c59a-53c2dcba9f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Help!\n",
      "मेरे पापा के बार सफ़रे के साथ रहते हों।\n",
      "\n",
      "-\n",
      "Jump.\n",
      "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
      "\n",
      "-\n",
      "Jump.\n",
      "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
      "\n",
      "-\n",
      "Jump.\n",
      "मेरी बात ने अभी अक्री नीजी नी मेे लिए कुछ नहीं है।\n",
      "\n",
      "-\n",
      "Hello!\n",
      "मेरे पापा के बार सफ़रे के साथ रहते हैं।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(5):\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print(input_texts[seq_index])\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1u0onnyUmY_6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

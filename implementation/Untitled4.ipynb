{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3vm735qPMek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932f24f5-1bef-4d7b-ac27-b1b71e4669f6"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "#print(os.listdir(\"/content/input\"))\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Kx4qJJwis8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8489cbb-e04e-4271-d5e1-aea3c4f672ef"
      },
      "source": [
        "#lines=pd.read_csv(\"/content/input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
        "lines = pd.read_csv(\"https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv\" , encoding='utf-8')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1b-YWPR_7F-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd01e8a4-6f9f-4e5e-fcd4-5f6796a71060"
      },
      "source": [
        "lines.rename(columns={'English' : 'english_sentence', 'Hindi': 'hindi_sentence'}, inplace=True)\n",
        "lines = lines[lines.columns[0:2]]\n",
        "lines.drop_duplicates(inplace=True)\n",
        "print(lines.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before : (124818, 2)\n",
            "Before : (124818, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsIJMEoeAR3R",
        "outputId": "4056badf-d183-4224-ebf9-28957b106aef"
      },
      "source": [
        "pd.isnull(lines).sum()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "english_sentence    0  \n",
              "hindi_sentence      311\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz2-uyWUAXsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b8d427-9049-4d16-9955-702b02512f15"
      },
      "source": [
        "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
        "lines=lines[~pd.isnull(lines['hindi_sentence'])]\n",
        "pd.isnull(lines).sum() , lines.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(english_sentence    0\n",
              " hindi_sentence      0\n",
              " dtype: int64, (124507, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAfL_YJOAg_S",
        "outputId": "ef0edfcc-2a5f-4caf-f86c-cb0489bbba5c"
      },
      "source": [
        "lines=lines.sample(n=25000,random_state=42)\n",
        "lines.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2FgzYf4Aub3"
      },
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUIp28ndAyHf"
      },
      "source": [
        "# Remove quotes\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_7vPEOyAymq"
      },
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Amv7GTRAypW"
      },
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "ZxaCfqhPAysn",
        "outputId": "87d4bc5d-b2bc-4e2b-de36-cef95ecbf274"
      },
      "source": [
        "# Add start and end tokens to target sequences\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n",
        "lines.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93994</th>\n",
              "      <td>it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous</td>\n",
              "      <td>START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124301</th>\n",
              "      <td>enceladus seen here</td>\n",
              "      <td>START_ एनसेलेडस पर इस जगह _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28869</th>\n",
              "      <td>ghanaian businessmen south african enterprising leaders</td>\n",
              "      <td>START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54938</th>\n",
              "      <td>the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers</td>\n",
              "      <td>START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>ismail afandi aka ismail khan of the ottoman empire designer of the main dome</td>\n",
              "      <td>START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                   english_sentence                                                                                                                                                                                                                       hindi_sentence\n",
              "93994   it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous                                                                  START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END                                                           \n",
              "124301  enceladus seen here                                                                                                                                                                                          START_ एनसेलेडस पर इस जगह _END                                                                                                                                                                                                     \n",
              "28869   ghanaian businessmen south african enterprising leaders                                                                                                                                                      START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END                                                                                                                          \n",
              "54938   the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers  START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END\n",
              "49997   ismail afandi aka ismail khan of the ottoman empire designer of the main dome                                                                                                                                START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END                                                                                                      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zff8kXHiBHdu"
      },
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in lines['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDcC9VybBHgm",
        "outputId": "4c97a9da-02d6-4157-b469-9b47fc961f8a"
      },
      "source": [
        "len(all_eng_words)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06FV0oAfBHkA",
        "outputId": "328a2ec6-8058-4761-f14b-bf4acbccb7e8"
      },
      "source": [
        "len(all_hindi_words)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpUKvpsRBH44"
      },
      "source": [
        "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Je1TQ4RBBH-1",
        "outputId": "cd447893-88fb-4a5e-94d9-308dbcd190df"
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93994</th>\n",
              "      <td>it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous</td>\n",
              "      <td>START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124301</th>\n",
              "      <td>enceladus seen here</td>\n",
              "      <td>START_ एनसेलेडस पर इस जगह _END</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28869</th>\n",
              "      <td>ghanaian businessmen south african enterprising leaders</td>\n",
              "      <td>START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54938</th>\n",
              "      <td>the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers</td>\n",
              "      <td>START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END</td>\n",
              "      <td>33</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>ismail afandi aka ismail khan of the ottoman empire designer of the main dome</td>\n",
              "      <td>START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                   english_sentence                                                                                                                                                                                                                       hindi_sentence  length_eng_sentence  length_hin_sentence\n",
              "93994   it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous                                                                  START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END                                                             23                   30                 \n",
              "124301  enceladus seen here                                                                                                                                                                                          START_ एनसेलेडस पर इस जगह _END                                                                                                                                                                                                       3                    6                  \n",
              "28869   ghanaian businessmen south african enterprising leaders                                                                                                                                                      START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END                                                                                                                            6                    19                 \n",
              "54938   the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers  START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END  33                   43                 \n",
              "49997   ismail afandi aka ismail khan of the ottoman empire designer of the main dome                                                                                                                                START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END                                                                                                        14                   20                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTuUb7A8BZOM",
        "outputId": "6212c8aa-cc9d-4adc-adf3-2ebfd836a441"
      },
      "source": [
        "lines[lines['length_eng_sentence']>30].shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2450, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-04ldtGwBZRL"
      },
      "source": [
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYbk8l_wBZT_",
        "outputId": "af09918f-8922-4175-ea39-117a91a52b59"
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16461, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFEQC_FPBZWu",
        "outputId": "f69aa1d2-ee93-4ba0-f8af-8e0c86f3b7c2"
      },
      "source": [
        "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
        "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maximum length of Hindi Sentence  20\n",
            "maximum length of English Sentence  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PRjzdMoBZZZ"
      },
      "source": [
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOfxvEVGBZcQ",
        "outputId": "56311f44-3ef0-4c1d-fbb2-63225e10d514"
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30829, 37434)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOW_Xph-BZev"
      },
      "source": [
        "num_decoder_tokens += 1 #for zero padding\n",
        "num_encoder_tokens = num_encoder_tokens + 1 #he forgot about this one he must have put it but deleted it by mistake"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPBcz5AiBZjg"
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAfq5kuGBZml"
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "xwyaWgomBZp2",
        "outputId": "3709afbd-c577-4c9a-de33-1bf939029ce8"
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99771</th>\n",
              "      <td>aids is one of those diseases about which we still have much to learn</td>\n",
              "      <td>START_ एड्स एक ऐसी बीमारी है जिसके बारे में हमें अभी बहुत कुछ जानना है _END</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39926</th>\n",
              "      <td>in the tajmahal was declared as unesco world heritage place</td>\n",
              "      <td>START_ में ताजमहल को युनेस्को विश्व धरोहर स्थल घोषित किया गया। _END</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66105</th>\n",
              "      <td>vedwyass g swpretham punycomma including anecdotes of men of a million srlokoan ah made india book</td>\n",
              "      <td>START_ वेदव्यास जी ने सर्वप्रथम पुण्यकर्मा मानवों के उपाख्यानों सहित एक लाख श्लोकों का आद्य भारत ग्रंथ बनाया। _END</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24064</th>\n",
              "      <td>the muslims call this day as pralay</td>\n",
              "      <td>START_ इसे मुसलमान प्रलय का दिन कहते हैं। _END</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106809</th>\n",
              "      <td>and if you ask a three yearold</td>\n",
              "      <td>START_ और अगर आप तीन साल के बच्चे से कहेंगे _END</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122456</th>\n",
              "      <td>and then percent average at</td>\n",
              "      <td>START_ और प्रतिशत पर उस समय _END</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75029</th>\n",
              "      <td>talking about things like gay marriage</td>\n",
              "      <td>START_ समलैंगिक विवाह जैसे विषयों की चर्चा में _END</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104602</th>\n",
              "      <td>now thats a great deal of us isnt it</td>\n",
              "      <td>START_ अब ये कोई बड़ी बात नहीं है _END</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10337</th>\n",
              "      <td>that was run by prostitutes</td>\n",
              "      <td>START_ जिसे वेश्याएँ मिल कर चलाती हैं। _END</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36587</th>\n",
              "      <td>he wrote one article when he was in jail that why he was an atheist</td>\n",
              "      <td>START_ उन्होंने जेल में अंग्रेज़ी में एक लेख भी लिखा जिसका शीर्षक था मैं नास्तिक क्यों हूँ। _END</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                          english_sentence                                                                                                      hindi_sentence  length_eng_sentence  length_hin_sentence\n",
              "99771   aids is one of those diseases about which we still have much to learn                               START_ एड्स एक ऐसी बीमारी है जिसके बारे में हमें अभी बहुत कुछ जानना है _END                                         14                   16                 \n",
              "39926   in the tajmahal was declared as unesco world heritage place                                         START_ में ताजमहल को युनेस्को विश्व धरोहर स्थल घोषित किया गया। _END                                                 10                   12                 \n",
              "66105   vedwyass g swpretham punycomma including anecdotes of men of a million srlokoan ah made india book  START_ वेदव्यास जी ने सर्वप्रथम पुण्यकर्मा मानवों के उपाख्यानों सहित एक लाख श्लोकों का आद्य भारत ग्रंथ बनाया। _END  16                   19                 \n",
              "24064   the muslims call this day as pralay                                                                 START_ इसे मुसलमान प्रलय का दिन कहते हैं। _END                                                                      7                    9                  \n",
              "106809  and if you ask a three yearold                                                                      START_ और अगर आप तीन साल के बच्चे से कहेंगे _END                                                                    7                    11                 \n",
              "122456  and then percent average at                                                                         START_ और प्रतिशत पर उस समय _END                                                                                    5                    7                  \n",
              "75029   talking about things like gay marriage                                                              START_ समलैंगिक विवाह जैसे विषयों की चर्चा में _END                                                                 6                    9                  \n",
              "104602  now thats a great deal of us isnt it                                                                START_ अब ये कोई बड़ी बात नहीं है _END                                                                              9                    9                  \n",
              "10337   that was run by prostitutes                                                                         START_ जिसे वेश्याएँ मिल कर चलाती हैं। _END                                                                         5                    8                  \n",
              "36587   he wrote one article when he was in jail that why he was an atheist                                 START_ उन्होंने जेल में अंग्रेज़ी में एक लेख भी लिखा जिसका शीर्षक था मैं नास्तिक क्यों हूँ। _END                    15                   18                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFpvhMdCBwf",
        "outputId": "a96492ad-1e02-42d5-851d-c2c5801e4fbc"
      },
      "source": [
        "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13168,), (3293,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_6Cd6r1CBzX"
      },
      "source": [
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tE4qZdlCB2N"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxBGI9ACB5E"
      },
      "source": [
        "latent_dim=300"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwFMMEWgCB78"
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYlfN0wMCB--"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEzjN-IICCBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb748ab-8ad0-4c98-c84e-62205b9422ea"
      },
      "source": [
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size)\n",
        "\n",
        "# Create a new model instance\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples/batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples/batch_size,callbacks=[cp_callback])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    9249000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    11230500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 37435)  11267935    lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 33,189,835\n",
            "Trainable params: 33,189,835\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "102/102 [==============================] - 85s 475ms/step - loss: 4.0930 - val_loss: 3.4967\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 45s 441ms/step - loss: 3.4893 - val_loss: 3.4316\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 45s 442ms/step - loss: 3.3501 - val_loss: 3.3342\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 44s 428ms/step - loss: 3.2105 - val_loss: 3.2734\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 44s 431ms/step - loss: 3.0929 - val_loss: 3.2345\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 45s 434ms/step - loss: 2.9900 - val_loss: 3.2246\n",
            "Epoch 7/30\n",
            " 22/102 [=====>........................] - ETA: 30s - loss: 2.9506\n",
            "Epoch 00007: saving model to training_2/cp-0007.ckpt\n",
            "102/102 [==============================] - 45s 442ms/step - loss: 2.8969 - val_loss: 3.1836\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 44s 430ms/step - loss: 2.8081 - val_loss: 3.1744\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 45s 437ms/step - loss: 2.7220 - val_loss: 3.1570\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 43s 419ms/step - loss: 2.6396 - val_loss: 3.1481\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 44s 433ms/step - loss: 2.5583 - val_loss: 3.1397\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 45s 437ms/step - loss: 2.4789 - val_loss: 3.1359\n",
            "Epoch 13/30\n",
            " 44/102 [===========>..................] - ETA: 22s - loss: 2.4262\n",
            "Epoch 00013: saving model to training_2/cp-0013.ckpt\n",
            "102/102 [==============================] - 45s 439ms/step - loss: 2.4009 - val_loss: 3.1346\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 44s 433ms/step - loss: 2.3254 - val_loss: 3.1326\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 45s 435ms/step - loss: 2.2476 - val_loss: 3.1364\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 44s 430ms/step - loss: 2.1729 - val_loss: 3.1294\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 44s 423ms/step - loss: 2.0977 - val_loss: 3.1422\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 44s 431ms/step - loss: 2.0214 - val_loss: 3.1446\n",
            "Epoch 19/30\n",
            " 66/102 [==================>...........] - ETA: 14s - loss: 1.9562\n",
            "Epoch 00019: saving model to training_2/cp-0019.ckpt\n",
            "102/102 [==============================] - 46s 448ms/step - loss: 1.9476 - val_loss: 3.1546\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 44s 425ms/step - loss: 1.8746 - val_loss: 3.1684\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 44s 432ms/step - loss: 1.8022 - val_loss: 3.1696\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 45s 434ms/step - loss: 1.7321 - val_loss: 3.1927\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 45s 441ms/step - loss: 1.6632 - val_loss: 3.2019\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 44s 427ms/step - loss: 1.5947 - val_loss: 3.2288\n",
            "Epoch 25/30\n",
            " 88/102 [========================>.....] - ETA: 5s - loss: 1.5305\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "102/102 [==============================] - 45s 441ms/step - loss: 1.5278 - val_loss: 3.2319\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 45s 438ms/step - loss: 1.4627 - val_loss: 3.2422\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 45s 441ms/step - loss: 1.3962 - val_loss: 3.2678\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 45s 436ms/step - loss: 1.3347 - val_loss: 3.2857\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 45s 437ms/step - loss: 1.2727 - val_loss: 3.2981\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 44s 430ms/step - loss: 1.2124 - val_loss: 3.3092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f054c201550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bp2gGL_f6jI",
        "outputId": "e71c32fa-1d7d-4f8b-fa06-9fa9ba6bbbf3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylrz0UKr-_3z"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/ColabNotebooks/nmt_weights21.h5')\n",
        "model.save('/content/drive/MyDrive/ColabNotebooks/nmt_weights21save.h5')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_oBnUFvMd4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e837594-01b7-4ca7-e5db-da066bd21a4c"
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model = load_model('/content/drive/MyDrive/ColabNotebooks/nmt_weights21save.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    9249000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    11230500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 37435)  11267935    lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 33,189,835\n",
            "Trainable params: 33,189,835\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrPSFxRxNjEA",
        "outputId": "84831cf9-0b08-4d78-e496-bdd5e6191ddb"
      },
      "source": [
        "#new_model = load_model(filepath)'\n",
        "\n",
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0007.ckpt.data-00000-of-00001',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0007.ckpt.index',\n",
              " 'cp-0019.ckpt.index',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0019.ckpt.data-00000-of-00001',\n",
              " 'cp-0013.ckpt.index',\n",
              " 'cp-0013.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "X5NiJVlnFAVt",
        "outputId": "90b8a9bf-fbda-4d2d-a9da-98bce3919473"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training_2/cp-0025.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "NXNMq8rcm9Zc",
        "outputId": "861bf04f-e071-47be-e52a-fa9b7b5a5276"
      },
      "source": [
        "# X_test = X_test.apply(lambda x: str(x))\n",
        "# y_test = y_test.apply(lambda x: str(x))\n",
        "X_test = X_test.astype(str)\n",
        "y_test = y_test.astype(str)\n",
        "X_test[:1][0]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-646912767e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "j1_vvTn4Fxrm",
        "outputId": "768efe13-0cca-4773-84f1-a33f233d1784"
      },
      "source": [
        "#nmodel = create_model()\n",
        "#nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# Load the previously saved weights\n",
        "#nmodel.load_weights(latest)\n",
        "print(X_test.dtypes , X_train.dtypes, y_test.dtypes, y_train.dtypes)\n",
        "loss, acc = model.evaluate([X_test, y_test], batch_size=128)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object object object object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-f77881a6d1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#nmodel.load_weights(latest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restored model, accuracy: {:5.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node model/Cast (defined at <ipython-input-72-5dadb232926c>:5) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_32498]\n\nFunction call stack:\ntest_function -> test_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_OU8tZQmcmu"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "CHJGGv0rLgXE",
        "outputId": "158c1a0b-3276-46fe-bc15-3c4801aa5271"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/nmt_weights.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-2ca0c3c20052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/nmt_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Show the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load_model() got an unexpected keyword argument 'weights'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR8Ev0ZYCCQf"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1221OdjHQPn"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbGN6AysHQSt"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwczifSVHQVl",
        "outputId": "4c7a99d6-a7c3-4248-8b2e-9d585a07c7a0"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: thats the first time in india\n",
            "Actual Hindi Translation:  भारत में ये पहली बार हुआ \n",
            "Predicted Hindi Translation:  भारत में यह पहली बार हुआ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc8cmfypHQY4",
        "outputId": "2186f32c-45f9-46a5-e3df-5d88eb898e7a"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: i was waiting and when he did emerge\n",
            "Actual Hindi Translation:  मैं इन्तेज़ार कर रहा था और जब वो आया \n",
            "Predicted Hindi Translation:  मैं कैसे मार्गदर्शन जब मैं कहना गया था \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mirHKcLaHQb_",
        "outputId": "f9826c44-4ec9-4484-fcc9-c397be978a13"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: whod never been interested in art\n",
            "Actual Hindi Translation:  जिसे कला में बिल्कुल भी रूचि नहीं थी \n",
            "Predicted Hindi Translation:  जिसे कला में कभी भी ऐसा नहीं थी \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX9OzAMYHQhc",
        "outputId": "69fef455-7594-4d17-f9e6-70f88a1a345f"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: it saves lives\n",
            "Actual Hindi Translation:  यह जीवन बचाता है \n",
            "Predicted Hindi Translation:  यह जीवन \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
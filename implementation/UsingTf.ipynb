{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2594,
     "status": "ok",
     "timestamp": 1620288581655,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "sxfp7uveRaWK",
    "outputId": "bf3b9214-36b6-4759-e64a-87af98cd5133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Before :  {')', '?', '%', '_', '$', '\"', '-', '}', '\\\\', '+', '|', '#', '=', '/', '~', '@', '[', '*', ':', ';', '`', ']', '>', '(', '<', ',', \"'\", '!', '{', '^', '&', '.'}\n",
      "After :  {')', '%', '_', '$', '\"', '-', '}', '\\\\', '+', '#', '=', '/', '~', '@', '[', '*', ':', ';', '`', ']', '>', '(', '<', \"'\", '{', '^', '&'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import string\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "punctuations = set(string.punctuation)\n",
    "not_punc = \".?!,|\"\n",
    "print(\"Before : \", punctuations)\n",
    "for c in not_punc:\n",
    "   punctuations.remove(c)\n",
    "print(\"After : \", punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6849,
     "status": "ok",
     "timestamp": 1620288585922,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "lDexzOIMSY1b",
    "outputId": "24d2762d-7ab0-4ca3-e700-1757deb22423"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['English', 'Hindi'], dtype='object'), (127607, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('English_hindi.csv', encoding='utf-8') #https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv\n",
    "df = df[df.columns[0:2]]\n",
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6841,
     "status": "ok",
     "timestamp": 1620288585922,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "WtMsl7LtIk4R",
    "outputId": "767adef1-e365-4975-da7e-c9d48af6c78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124818, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~pd.isnull(df['English'])]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6836,
     "status": "ok",
     "timestamp": 1620288585925,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "YTObn4tXx-Gg",
    "outputId": "3e864484-a01e-4fab-b94a-aed08d51f63c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate number of words in each line of 2 columns\n",
    "df['len_eng_words'] = df['English'].apply(lambda e: len(str(e).split(\" \")))\n",
    "df['len_hin_words'] = df['Hindi'].apply(lambda h: len(str(h).split(\" \")))\n",
    "df = df[df['len_eng_words']<=20]\n",
    "df = df[df['len_hin_words']<=20]\n",
    "max(df['len_eng_words']), max(df['len_hin_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6830,
     "status": "ok",
     "timestamp": 1620288585926,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "SOwcB8OaJRur",
    "outputId": "66d26319-03e4-4c19-dcdf-a3a7c5b77afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=5000, random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6828,
     "status": "ok",
     "timestamp": 1620288585927,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "c1eJw7PiHx1C"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence_hindi(w):\n",
    "    w = str(w).lower().strip()\n",
    "    w = re.sub(r\"[\\(\\[].*?[\\)\\]]\", '', w)\n",
    "    w = re.sub(r\"[२३०८१५७९४६]\", '', w)\n",
    "    #creating a space between a word and punctuation \n",
    "    w = re.sub(r\"([?!,|])\", r' \\1 ', w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = ''.join(c for c in w if c not in punctuations)\n",
    "            \n",
    "    # # replacing everything with space except a-z A-Z ? . ! , |\n",
    "    #w = re.sub(r'[^a-z?|!,]', \" \", w)\n",
    "    w = w.strip()\n",
    "\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def preprocess_sentence_eng(w):#https://www.tfaforms.com/4844143\n",
    "    w = unicode_to_ascii(str(w).lower().strip())\n",
    "    w = re.sub(r\"[\\(\\[].*?[\\)\\]]\", '', w)\n",
    "    #creating a space between a word and punctuation \n",
    "    w = re.sub(r\"([.?!,])\", r' \\1 ', w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # # replacing everything with space except a-z A-Z ? . ! , |\n",
    "    w = re.sub(r'[^a-zA-Z?.!,]+', \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 6827,
     "status": "ok",
     "timestamp": 1620288585929,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "Em6wAlDRMmJt"
   },
   "outputs": [],
   "source": [
    "def customize_dataset(df):\n",
    "    df['English'] = df['English'].apply(lambda e : preprocess_sentence_eng(e))\n",
    "    df['Hindi'] = df['Hindi'].apply(lambda h : preprocess_sentence_hindi(h))\n",
    "\n",
    "    return df['English'], df['Hindi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 6827,
     "status": "ok",
     "timestamp": 1620288585931,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "FDyTVaa0y2kX"
   },
   "outputs": [],
   "source": [
    "def tokenizer(data_sen):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(data_sen)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(data_sen)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6825,
     "status": "ok",
     "timestamp": 1620288585932,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "jIzgJRfnMSs1"
   },
   "outputs": [],
   "source": [
    "def load_dataset(df):\n",
    "    input_lang, target_lang = customize_dataset(df)\n",
    "\n",
    "    input_tf, input_lang_tokenizer = tokenizer(input_lang)\n",
    "    target_tf, target_lang_tokenizer = tokenizer(target_lang)\n",
    "\n",
    "    return input_tf, target_tf, input_lang_tokenizer, target_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 9590,
     "status": "ok",
     "timestamp": 1620288588700,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "aUyAzy9JfphH"
   },
   "outputs": [],
   "source": [
    "input_tf, target_tf, input_lang_tokenizer, target_lang_tokenizer = load_dataset(df)\n",
    "\n",
    "max_input_len , max_target_len = input_tf.shape[1], target_tf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9587,
     "status": "ok",
     "timestamp": 1620288588703,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "_WKjK-XnhHtQ",
    "outputId": "7f7100fb-b011-4966-8e9a-df590a5ba389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1000, 4000, 1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Train test split\n",
    "input_tf_train, input_tf_test, target_tf_train, target_tf_test = train_test_split(input_tf, target_tf, test_size=0.2)\n",
    "\n",
    "len(input_tf_train), len(input_tf_test), len(target_tf_train), len(target_tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9583,
     "status": "ok",
     "timestamp": 1620288588706,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "vG71hj7Qjbv8",
    "outputId": "608215ae-bc0d-4f37-ded4-f896e9340478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input lang : index to word mapping\n",
      "1 ----> <start>\n",
      "680 ----> thank\n",
      "17 ----> you\n",
      "5089 ----> industrialization\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "target lang : index to word mapping\n",
      "1 ----> <start>\n",
      "6130 ----> “औद्योगिकीकरण\n",
      "969 ----> धन्यवाद\n",
      "32 ----> |\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "           print(f'{t} ----> {lang.index_word[t]}')\n",
    "\n",
    "print('Input lang : index to word mapping')\n",
    "convert(input_lang_tokenizer, input_tf_train[0])\n",
    "\n",
    "print('target lang : index to word mapping')\n",
    "convert(target_lang_tokenizer, target_tf_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 14723,
     "status": "ok",
     "timestamp": 1620288593849,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "ZiYzXT0YkqPC"
   },
   "outputs": [],
   "source": [
    "# Creating Dataset\n",
    "BUFFER_SIZE = len(input_tf_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epochs = len(input_tf_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units=1024\n",
    "vocab_inp_size = len(input_lang_tokenizer.word_index) +1 \n",
    "vocab_tar_size =  len(target_lang_tokenizer.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tf_train, target_tf_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14725,
     "status": "ok",
     "timestamp": 1620288593856,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "h1cpISGpVJ4N",
    "outputId": "3751b421-3c9d-41a3-daf2-37fe665b07f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 32]), TensorShape([64, 25]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 14729,
     "status": "ok",
     "timestamp": 1620288593862,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "2eP0bidVJ3Rs"
   },
   "outputs": [],
   "source": [
    " class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.enc_units = enc_units\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.enc_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43205,
     "status": "ok",
     "timestamp": 1620288622344,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "dafZUos6f3th",
    "outputId": "d5cc721e-a26b-4824-962e-1dcd8e5eef9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output (Batch_size, seq_len, units) (64, 32, 1024)\n",
      "Encoder Output (Batch_size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Sample input \n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder Output (Batch_size, seq_len, units)', sample_output.shape)\n",
    "print('Encoder Output (Batch_size, units)', sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 43207,
     "status": "ok",
     "timestamp": 1620288622349,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "P_kxNFhDiROd"
   },
   "outputs": [],
   "source": [
    "class BahadanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahadanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46105,
     "status": "ok",
     "timestamp": 1620288625253,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "vsrd3hTtnVaZ",
    "outputId": "4f222573-71ed-49d2-dceb-6a691a706860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape (Batch_size, units) (64, 1024)\n",
      "Attention weights shape (Batch_size, seq_len, 1) (64, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahadanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print('Attention result shape (Batch_size, units)', attention_result.shape)\n",
    "print('Attention weights shape (Batch_size, seq_len, 1)', attention_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 46106,
     "status": "ok",
     "timestamp": 1620288625256,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "A2-UmjvzrrVQ"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)    \n",
    "        self.dec_units = dec_units\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Used for Attenation\n",
    "        self.attention = BahadanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_len, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46101,
     "status": "ok",
     "timestamp": 1620288625258,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "nKBl_OT-lj8U",
    "outputId": "917b4c56-9f2d-418a-de28-523cea8ccbdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 10008)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "\n",
    "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 46100,
     "status": "ok",
     "timestamp": 1620288625260,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "iTnxT3MTmUFR"
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function \n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 46101,
     "status": "ok",
     "timestamp": 1620288625263,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "zMcACqtUp2sc"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = '/run/media/pacman/9C3D62B805200142/Neural'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 46100,
     "status": "ok",
     "timestamp": 1620288625265,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "DtifD4pZrH-S"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543170,
     "status": "ok",
     "timestamp": 1620301103017,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "PXqpA38jtgCh",
    "outputId": "6d24e8d4-468c-4415-b53e-098b4cb82b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7f3317976820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp3q0jj2ih.py, line 28)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_step at 0x7f3317976820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp3q0jj2ih.py, line 28)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1 Batch 0 Loss 3.9263\n",
      "Epoch 1 Loss 3.2113\n",
      "Time taken for 1 epoch 362.41 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.9643\n",
      "Epoch 2 Loss 2.8992\n",
      "Time taken for 1 epoch 297.38 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.2308\n",
      "Epoch 3 Loss 2.7490\n",
      "Time taken for 1 epoch 290.36 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.5722\n",
      "Epoch 4 Loss 2.6016\n",
      "Time taken for 1 epoch 295.07 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.2150\n",
      "Epoch 5 Loss 2.4427\n",
      "Time taken for 1 epoch 297.42 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.5717\n",
      "Epoch 6 Loss 2.2941\n",
      "Time taken for 1 epoch 293.49 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.0573\n",
      "Epoch 7 Loss 2.1390\n",
      "Time taken for 1 epoch 290.89 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.9912\n",
      "Epoch 8 Loss 1.9879\n",
      "Time taken for 1 epoch 292.40 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7493\n",
      "Epoch 9 Loss 1.8348\n",
      "Time taken for 1 epoch 289.23 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.5091\n",
      "Epoch 10 Loss 1.6711\n",
      "Time taken for 1 epoch 292.33 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.2860\n",
      "Epoch 11 Loss 1.5107\n",
      "Time taken for 1 epoch 288.88 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.2120\n",
      "Epoch 12 Loss 1.3463\n",
      "Time taken for 1 epoch 292.19 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.2017\n",
      "Epoch 13 Loss 1.1932\n",
      "Time taken for 1 epoch 287.48 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9443\n",
      "Epoch 14 Loss 1.0479\n",
      "Time taken for 1 epoch 290.48 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.8803\n",
      "Epoch 15 Loss 0.9119\n",
      "Time taken for 1 epoch 286.76 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6965\n",
      "Epoch 16 Loss 0.7872\n",
      "Time taken for 1 epoch 289.60 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.5909\n",
      "Epoch 17 Loss 0.6723\n",
      "Time taken for 1 epoch 286.91 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4972\n",
      "Epoch 18 Loss 0.5689\n",
      "Time taken for 1 epoch 290.31 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.4645\n",
      "Epoch 19 Loss 0.4759\n",
      "Time taken for 1 epoch 287.01 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.3059\n",
      "Epoch 20 Loss 0.4002\n",
      "Time taken for 1 epoch 293.09 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.2731\n",
      "Epoch 21 Loss 0.3238\n",
      "Time taken for 1 epoch 296.29 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.2331\n",
      "Epoch 22 Loss 0.2551\n",
      "Time taken for 1 epoch 300.96 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.1644\n",
      "Epoch 23 Loss 0.2010\n",
      "Time taken for 1 epoch 294.95 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.1703\n",
      "Epoch 24 Loss 0.1565\n",
      "Time taken for 1 epoch 300.37 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.1094\n",
      "Epoch 25 Loss 0.1242\n",
      "Time taken for 1 epoch 296.17 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.1098\n",
      "Epoch 26 Loss 0.0962\n",
      "Time taken for 1 epoch 299.74 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0617\n",
      "Epoch 27 Loss 0.0738\n",
      "Time taken for 1 epoch 295.38 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0594\n",
      "Epoch 28 Loss 0.0588\n",
      "Time taken for 1 epoch 298.84 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0401\n",
      "Epoch 29 Loss 0.0458\n",
      "Time taken for 1 epoch 295.33 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0296\n",
      "Epoch 30 Loss 0.0383\n",
      "Time taken for 1 epoch 299.27 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0243\n",
      "Epoch 31 Loss 0.0306\n",
      "Time taken for 1 epoch 294.08 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0160\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epochs)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epochs:.4f}')\n",
    "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1984,
     "status": "ok",
     "timestamp": 1620302059005,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "gfrK3dtbtpUf"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_len, max_input_len))\n",
    "\n",
    "  sentence = preprocess_sentence_eng(sentence)\n",
    "\n",
    "  inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_input_len,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_target_len):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1620301103053,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "8A4vTM1vv-wF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1620301103055,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "2yKVEiDxwBlZ"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input:', sentence)\n",
    "  print('Predicted translation:', result)\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')),\n",
    "                                  :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1620301103056,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "zSuogXqbwFKE",
    "outputId": "f8db3e35-8b6f-4f03-94e3-0e7d6c16a39a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4773c5ebd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1620301103058,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "6FgQVPsDwJkR",
    "outputId": "fdac871e-0acf-435c-a2f8-063970304067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what is your name ? <end>\n",
      "Predicted translation: ? क़्या है ? <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2364 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2381 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2376 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2364 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2381 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2376 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'what is your name?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1620301103059,
     "user": {
      "displayName": "Rakesh S R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiU1Gz1ALtdbmqYAF9TWfM3x8QfnFXXSST0xb3BXg=s64",
      "userId": "15186136596477607928"
     },
     "user_tz": -330
    },
    "id": "NEJteMwD5jwx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPlcRxi1oJ3unFqoP7NO4Lt",
   "collapsed_sections": [],
   "mount_file_id": "1O0GGsXSlgg61x_y0KXSS1vm2ump7ibUg",
   "name": "UsingTf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResultPN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhSQB5kTNXIj",
        "outputId": "71073c24-b807-4e8b-a782-ad61640ff9b2"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        " \n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Qu8xtrN2ZY",
        "outputId": "5d1bb74e-fd01-4a0c-d040-cf0aed008482"
      },
      "source": [
        "# lines=pd.read_csv(\"/content/drive/MyDrive/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
        "url = 'https://raw.githubusercontent.com/prismspeechproject/neural/master/implementation/English_hindi.csv'\n",
        "lines=pd.read_csv(url, encoding='utf-8')\n",
        "lines= lines[lines.columns[0:2]]\n",
        "lines=lines[~pd.isnull(lines['English'])]\n",
        "lines=lines[~pd.isnull(lines['Hindi'])]\n",
        "lines.drop_duplicates(inplace=True)\n",
        "lines=lines.sample(n=25000,random_state=42)\n",
        "lines.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWVKuVwMOd4L"
      },
      "source": [
        "lines['English']=lines['English'].apply(lambda x: x.lower())\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__eLPt5OikU"
      },
      "source": [
        "\n",
        "lines['English']=lines['English'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axiD7EUOOlCj"
      },
      "source": [
        "exclude = set(string.punctuation) \n",
        "lines['English']=lines['English'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZG0cSsOnXO"
      },
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['English']=lines['English'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['Hindi'] = lines['Hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "lines['English']=lines['English'].apply(lambda x: x.strip())\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: x.strip())\n",
        "lines['English']=lines['English'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['Hindi']=lines['Hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "QiIRU5KJOqhL",
        "outputId": "e07344c7-1be4-4cc8-8ae8-2efb9414f3a7"
      },
      "source": [
        "\n",
        "lines['Hindi'] = lines['Hindi'].apply(lambda x : 'START_ '+ x + ' _END')\n",
        "lines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93994</th>\n",
              "      <td>it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous</td>\n",
              "      <td>START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124301</th>\n",
              "      <td>enceladus seen here</td>\n",
              "      <td>START_ एनसेलेडस पर इस जगह _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28869</th>\n",
              "      <td>ghanaian businessmen south african enterprising leaders</td>\n",
              "      <td>START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54938</th>\n",
              "      <td>the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers</td>\n",
              "      <td>START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>ismail afandi aka ismail khan of the ottoman empire designer of the main dome</td>\n",
              "      <td>START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                            English                                                                                                                                                                                                                                Hindi\n",
              "93994   it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous                                                                  START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END                                                           \n",
              "124301  enceladus seen here                                                                                                                                                                                          START_ एनसेलेडस पर इस जगह _END                                                                                                                                                                                                     \n",
              "28869   ghanaian businessmen south african enterprising leaders                                                                                                                                                      START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END                                                                                                                          \n",
              "54938   the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers  START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END\n",
              "49997   ismail afandi aka ismail khan of the ottoman empire designer of the main dome                                                                                                                                START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END                                                                                                      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UA5CKo2OuQy"
      },
      "source": [
        "\n",
        "all_eng_words=set()\n",
        "for eng in lines['English']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['Hindi']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJr_V-G2OyD7",
        "outputId": "393663f4-88f8-44db-848a-281f38c326f8"
      },
      "source": [
        "len(all_eng_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrs_Q7ieOy7e",
        "outputId": "01a64d2e-4f30-450d-bec7-13f00b4ca1a3"
      },
      "source": [
        "len(all_hindi_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvII-gQ-PAYJ"
      },
      "source": [
        "lines['length_eng_sentence']=lines['English'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['Hindi'].apply(lambda x:len(x.split(\" \")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "dE8rgGM0PEdh",
        "outputId": "a7fcc781-5e95-4768-affe-7e020e9f2b22"
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93994</th>\n",
              "      <td>it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous</td>\n",
              "      <td>START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124301</th>\n",
              "      <td>enceladus seen here</td>\n",
              "      <td>START_ एनसेलेडस पर इस जगह _END</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28869</th>\n",
              "      <td>ghanaian businessmen south african enterprising leaders</td>\n",
              "      <td>START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54938</th>\n",
              "      <td>the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers</td>\n",
              "      <td>START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END</td>\n",
              "      <td>33</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>ismail afandi aka ismail khan of the ottoman empire designer of the main dome</td>\n",
              "      <td>START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                            English                                                                                                                                                                                                                                Hindi  length_eng_sentence  length_hin_sentence\n",
              "93994   it is the land of festivals of different religions like diwali dushehra pongal and onam idulfitr muhrram chrimas ester are very much famous                                                                  START_ विभिन्न धर्मों के इस भूभाग पर कई मनभावन पर्व त्यौहार मनाए जाते हैं दिवाली होली दशहरा पोंगल तथा ओणम ईदउलफितर मुहर्रम क्रिसमस ईस्टर आदि भी काफ़ी लोकप्रिय हैं। _END                                                             23                   30                 \n",
              "124301  enceladus seen here                                                                                                                                                                                          START_ एनसेलेडस पर इस जगह _END                                                                                                                                                                                                       3                    6                  \n",
              "28869   ghanaian businessmen south african enterprising leaders                                                                                                                                                      START_ या फिर घाना के व्यवसायियों से या दक्षिण अफ्रिका के उद्योगों में अग्रणी भूमिका निभाने वालों से _END                                                                                                                            6                    19                 \n",
              "54938   the burma oil company processed the crude in its refinery at rangoon and distributed the products mainly kerosene through its tank installations at chief indian ports and through a fleet of steam tankers  START_ बर्मा आयल कंपनी अपनी रंगून की रिफाइनरी में कच्चे तेल को साफ करती थी और अपने उत्पादन का वितरण जो मुख़्यत मिट्टी का तेल था प्रधान भारतीय बंदरगाहों पर लगे टैंक प्रतिष्ठानों के द्वारा तथा स्टीम टैंकरों के द्वारा करती थी _END  33                   43                 \n",
              "49997   ismail afandi aka ismail khan of the ottoman empire designer of the main dome                                                                                                                                START_ मुख्य गुम्बद का अभिकल्पक इस्माइल एकाइस्माइल खाँ जो कि ऑट्टोमन साम्राज्य का प्रमुख गोलार्ध एवं गुम्बद अभिकल्पक थे। _END                                                                                                        14                   20                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UYfBtnSPHOB"
      },
      "source": [
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Yic0-btPJ6n",
        "outputId": "7d6c14c8-e998-4cd6-a50b-098bf90064bd"
      },
      "source": [
        "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
        "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maximum length of Hindi Sentence  20\n",
            "maximum length of English Sentence  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlwgKcUAPM1E"
      },
      "source": [
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHrXSf05PTT_",
        "outputId": "c018d3ed-1967-42c9-ca0c-28ca17987e44"
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30829, 37434)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIPlxUsPVdN"
      },
      "source": [
        "num_decoder_tokens += 1 \n",
        "num_encoder_tokens = num_encoder_tokens + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZLTfrRLPYJz"
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myDq4CvQPaja"
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Y45WqrdqPct7",
        "outputId": "09599bd4-dfa6-4ed2-9ef7-922c90f5e07e"
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66783</th>\n",
              "      <td>something that is absent in indopak engagement</td>\n",
              "      <td>START_ और भारतपाक वार्ता के बीच यही चीज नदारद है _END</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85524</th>\n",
              "      <td>these islands came under the administration of arzi hukumateazad hind the provisional government of free india</td>\n",
              "      <td>START_ यह द्वीप अर्जीहुकुमतएआजादहिंद के अनुशासन में रहें। _END</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9925</th>\n",
              "      <td>we need to face our fears and take back our streets</td>\n",
              "      <td>START_ हमें डर का सामना करना होगा और वापस अपनी सड़कों पर जाना होगा _END</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110753</th>\n",
              "      <td>the guess was percent which is</td>\n",
              "      <td>START_ अनुमान है कि प्रतिशत है जो है था _END</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94381</th>\n",
              "      <td>started as a teenager</td>\n",
              "      <td>START_ एक किशोर बालिका के रूप में शुरू हुई _END</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105623</th>\n",
              "      <td>this is sweet and full of juices</td>\n",
              "      <td>START_ यह मधुर और सरस है। _END</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9510</th>\n",
              "      <td>and i think that had something to do with giving me the courage</td>\n",
              "      <td>START_ मुझे लगता है कि कहीं तो इस बात ने मुझे हिम्मत भी जुगाई कि _END</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125265</th>\n",
              "      <td>due to oregon treaty with britain america got control over present american north west</td>\n",
              "      <td>START_ में ब्रिटेन के साथ हुई ओरेगॉन संधि के कारण अमेरिका को वर्तमान अमेरिकी उत्तरपश्चिम पर नियंत्रण मिला। _END</td>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31347</th>\n",
              "      <td>into areas of life that are not going too well</td>\n",
              "      <td>START_ पहलुओं के बारे में काफ़ी ज्ञान मिलेगा _END</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26524</th>\n",
              "      <td>“ here comes gautama our old teacher ” observed one of them</td>\n",
              "      <td>START_ उनमें से एक ने कहा देखो वह आ रहा है गौतम हमारा शिक्षक _END</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                               English                                                                                                            Hindi  length_eng_sentence  length_hin_sentence\n",
              "66783   something that is absent in indopak engagement                                                                  START_ और भारतपाक वार्ता के बीच यही चीज नदारद है _END                                                            7                    11                 \n",
              "85524   these islands came under the administration of arzi hukumateazad hind the provisional government of free india  START_ यह द्वीप अर्जीहुकुमतएआजादहिंद के अनुशासन में रहें। _END                                                   16                   9                  \n",
              "9925    we need to face our fears and take back our streets                                                             START_ हमें डर का सामना करना होगा और वापस अपनी सड़कों पर जाना होगा _END                                          11                   15                 \n",
              "110753  the guess was percent which is                                                                                  START_ अनुमान है कि प्रतिशत है जो है था _END                                                                     6                    10                 \n",
              "94381   started as a teenager                                                                                           START_ एक किशोर बालिका के रूप में शुरू हुई _END                                                                  4                    10                 \n",
              "105623  this is sweet and full of juices                                                                                START_ यह मधुर और सरस है। _END                                                                                   7                    7                  \n",
              "9510    and i think that had something to do with giving me the courage                                                 START_ मुझे लगता है कि कहीं तो इस बात ने मुझे हिम्मत भी जुगाई कि _END                                            13                   16                 \n",
              "125265  due to oregon treaty with britain america got control over present american north west                          START_ में ब्रिटेन के साथ हुई ओरेगॉन संधि के कारण अमेरिका को वर्तमान अमेरिकी उत्तरपश्चिम पर नियंत्रण मिला। _END  14                   19                 \n",
              "31347   into areas of life that are not going too well                                                                  START_ पहलुओं के बारे में काफ़ी ज्ञान मिलेगा _END                                                                10                   9                  \n",
              "26524   “ here comes gautama our old teacher ” observed one of them                                                     START_ उनमें से एक ने कहा देखो वह आ रहा है गौतम हमारा शिक्षक _END                                                12                   15                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQmUqNgwPfCD",
        "outputId": "618e65a4-ce12-491f-b001-e968dc6b6a3a"
      },
      "source": [
        "X, y = lines['English'], lines['Hindi']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13168,), (3293,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XXetW1NPhmd"
      },
      "source": [
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzHWN4FYPkst"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGcjLiK-PnHW"
      },
      "source": [
        "latent_dim=300\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDsciYUTPrZi"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "goTwXxdlPt1d",
        "outputId": "4151af40-376e-436c-84e4-e7fd298cc3f3"
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "epochs = 100\n",
        "batch_size =128\n",
        "# checkpoint_path = \"/content/drive/MyDrive/Colab/ResultPNBy/\" /training_2/cp-{epoch:04d}.ckpt\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_path, \n",
        "#     verbose=1, \n",
        "#     save_weights_only=True,\n",
        "#     save_freq=5*batch_size)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples/batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples/batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    9249000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    11230500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 37435)  11267935    lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 33,189,835\n",
            "Trainable params: 33,189,835\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 66s 410ms/step - loss: 4.0690 - val_loss: 3.5805\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 3.4631 - val_loss: 3.5108\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 44s 431ms/step - loss: 3.3284 - val_loss: 3.4123\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 44s 432ms/step - loss: 3.1836 - val_loss: 3.3530\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 41s 396ms/step - loss: 3.0660 - val_loss: 3.3135\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 45s 440ms/step - loss: 2.9637 - val_loss: 3.2901\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 41s 397ms/step - loss: 2.8710 - val_loss: 3.2671\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 40s 393ms/step - loss: 2.7832 - val_loss: 3.2579\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 44s 431ms/step - loss: 2.6987 - val_loss: 3.2420\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 2.6161 - val_loss: 3.2410\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 41s 397ms/step - loss: 2.5331 - val_loss: 3.2262\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 40s 394ms/step - loss: 2.4513 - val_loss: 3.2192\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 41s 395ms/step - loss: 2.3704 - val_loss: 3.2240\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 40s 389ms/step - loss: 2.2926 - val_loss: 3.2128\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 2.2181 - val_loss: 3.2186\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 41s 395ms/step - loss: 2.1416 - val_loss: 3.2260\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 40s 390ms/step - loss: 2.0660 - val_loss: 3.2256\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 44s 430ms/step - loss: 1.9958 - val_loss: 3.2430\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 40s 389ms/step - loss: 1.9209 - val_loss: 3.2454\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 1.8528 - val_loss: 3.2613\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 39s 383ms/step - loss: 1.7817 - val_loss: 3.2757\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 1.7112 - val_loss: 3.2762\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 40s 389ms/step - loss: 1.6457 - val_loss: 3.3110\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 1.5760 - val_loss: 3.3149\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 40s 385ms/step - loss: 1.5130 - val_loss: 3.3288\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 1.4464 - val_loss: 3.3394\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 40s 389ms/step - loss: 1.3802 - val_loss: 3.3576\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 1.3198 - val_loss: 3.3854\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 39s 384ms/step - loss: 1.2579 - val_loss: 3.3929\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 44s 425ms/step - loss: 1.1983 - val_loss: 3.4237\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 1.1409 - val_loss: 3.4355\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 1.0846 - val_loss: 3.4521\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 1.0273 - val_loss: 3.4842\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 45s 435ms/step - loss: 0.9742 - val_loss: 3.4961\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 40s 385ms/step - loss: 0.9210 - val_loss: 3.5112\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.8712 - val_loss: 3.5537\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.8217 - val_loss: 3.5602\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.7776 - val_loss: 3.5934\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 39s 383ms/step - loss: 0.7273 - val_loss: 3.6102\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.6872 - val_loss: 3.6341\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 39s 384ms/step - loss: 0.6421 - val_loss: 3.6497\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 40s 389ms/step - loss: 0.6011 - val_loss: 3.6816\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 39s 385ms/step - loss: 0.5643 - val_loss: 3.7164\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 39s 383ms/step - loss: 0.5258 - val_loss: 3.7268\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.4907 - val_loss: 3.7650\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 41s 397ms/step - loss: 0.4570 - val_loss: 3.7830\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.4231 - val_loss: 3.8004\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 39s 383ms/step - loss: 0.3954 - val_loss: 3.8351\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 40s 390ms/step - loss: 0.3645 - val_loss: 3.8442\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 39s 385ms/step - loss: 0.3391 - val_loss: 3.8880\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.3098 - val_loss: 3.8928\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.2872 - val_loss: 3.9335\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.2633 - val_loss: 3.9413\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.2428 - val_loss: 3.9639\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 0.2207 - val_loss: 3.9918\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.2025 - val_loss: 4.0161\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.1840 - val_loss: 4.0382\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 44s 430ms/step - loss: 0.1699 - val_loss: 4.0745\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 40s 390ms/step - loss: 0.1539 - val_loss: 4.0874\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 39s 385ms/step - loss: 0.1409 - val_loss: 4.1062\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.1279 - val_loss: 4.1393\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.1163 - val_loss: 4.1613\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 40s 385ms/step - loss: 0.1056 - val_loss: 4.1890\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.0959 - val_loss: 4.2060\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.0865 - val_loss: 4.2256\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 44s 432ms/step - loss: 0.0791 - val_loss: 4.2454\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 44s 427ms/step - loss: 0.0712 - val_loss: 4.2672\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.0655 - val_loss: 4.2838\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 39s 384ms/step - loss: 0.0598 - val_loss: 4.3046\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 40s 394ms/step - loss: 0.0521 - val_loss: 4.3216\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.0477 - val_loss: 4.3447\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.0445 - val_loss: 4.3619\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.0413 - val_loss: 4.3855\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.0368 - val_loss: 4.3916\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.0332 - val_loss: 4.4095\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 40s 384ms/step - loss: 0.0316 - val_loss: 4.4371\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 44s 428ms/step - loss: 0.0287 - val_loss: 4.4441\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 40s 390ms/step - loss: 0.0270 - val_loss: 4.4532\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.0255 - val_loss: 4.4681\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 44s 424ms/step - loss: 0.0227 - val_loss: 4.4774\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 0.0204 - val_loss: 4.5224\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.0197 - val_loss: 4.5254\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 40s 388ms/step - loss: 0.0182 - val_loss: 4.5356\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 40s 385ms/step - loss: 0.0162 - val_loss: 4.5516\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 40s 392ms/step - loss: 0.0157 - val_loss: 4.5648\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 39s 382ms/step - loss: 0.0149 - val_loss: 4.5887\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 40s 386ms/step - loss: 0.0139 - val_loss: 4.6029\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 40s 391ms/step - loss: 0.0135 - val_loss: 4.6034\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 40s 387ms/step - loss: 0.0125 - val_loss: 4.6215\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 40s 384ms/step - loss: 0.0120 - val_loss: 4.6424\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 40s 385ms/step - loss: 0.0114 - val_loss: 4.6443\n",
            "Epoch 92/100\n",
            " 52/102 [==============>...............] - ETA: 16s - loss: 0.0098"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-71bda5471385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     validation_steps = val_samples/batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqve1DcWsPS9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu0WDaNWPwWU"
      },
      "source": [
        "import keras\n",
        "model.save('/content/drive/MyDrive/Colab/ResultPNA2.h5')\n",
        "# model = keras.models.load_model('/content/drive/MyDrive/ColabNotebooks/ResultPN.h5')\n",
        "new_model = keras.models.load_model('/content/drive/MyDrive/Colab/ResultPNA2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlUe6ZakJguU"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/Colab/ResultPNA2Weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61EJxUcRny7"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNmVd5nn8eKG"
      },
      "source": [
        "# new_model.get_weights()\n",
        "decoder_model.save_weights('/content/drive/MyDrive/Colab/ResultPNA2DecoderModelW.h5')\n",
        "# decoder_model.save('/content/drive/MyDrive/Colab/ResultPNA2DecoderModel.h5')\n",
        "encoder_model.save_weights('/content/drive/MyDrive/Colab/ResultPNA2EncoderModelW.h5')\n",
        "\n",
        "# import keras\n",
        "# encoder1_model = keras.loa('/content/drive/MyDrive/Colab/ResultPNA2EncoderModelW.h5')\n",
        "# decoder1_model = keras.Model.load_weights(new_model, filepath='/content/drive/MyDrive/Colab/ResultPNA2DecoderModelW.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTpJAhxz_ymD",
        "outputId": "ec1161eb-e41b-4cb6-fdf3-743f56e9eb18"
      },
      "source": [
        "encoder_model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.03278746, -0.04713671,  0.04531088, ...,  0.03735603,\n",
              "          0.04260695, -0.03743915],\n",
              "        [-0.04260749, -0.04618214,  0.06512512, ...,  0.03285646,\n",
              "         -0.16743907,  0.17625006],\n",
              "        [-0.0256097 ,  0.0101689 , -0.02973282, ...,  0.06225212,\n",
              "          0.00446727,  0.06319299],\n",
              "        ...,\n",
              "        [ 0.09077454, -0.15649116,  0.01506825, ..., -0.03724433,\n",
              "          0.06550077,  0.13268104],\n",
              "        [ 0.02333522,  0.09466827, -0.065641  , ...,  0.07773712,\n",
              "         -0.0386913 ,  0.12254772],\n",
              "        [-0.09309627, -0.00038396,  0.04899064, ...,  0.02046278,\n",
              "          0.05504965, -0.02658486]], dtype=float32),\n",
              " array([[-0.04894491,  0.43890646,  0.14557324, ..., -0.2037875 ,\n",
              "         -0.05536366,  0.04763384],\n",
              "        [-0.23519029, -0.28390932, -0.06006496, ..., -0.26280534,\n",
              "         -0.00966674, -0.04627035],\n",
              "        [-0.13937916,  0.06998777, -0.21449183, ...,  0.01371102,\n",
              "         -0.09854786, -0.03401583],\n",
              "        ...,\n",
              "        [-0.10170906, -0.3826086 , -0.09449928, ..., -0.13260986,\n",
              "         -0.1650826 , -0.00977501],\n",
              "        [-0.09772353,  0.19718508,  0.05542789, ...,  0.05525403,\n",
              "          0.09825117, -0.08068822],\n",
              "        [-0.05173208, -0.4922654 , -0.02678311, ..., -0.00634782,\n",
              "         -0.20702764, -0.18851748]], dtype=float32),\n",
              " array([[-0.12815003,  0.01197892, -0.0876217 , ..., -0.09424297,\n",
              "         -0.14039831,  0.40064806],\n",
              "        [ 0.01197693,  0.00910382,  0.09055764, ..., -0.05891882,\n",
              "          0.04280421,  0.17010014],\n",
              "        [ 0.00131562,  0.13833039, -0.00182201, ...,  0.05664522,\n",
              "          0.02433369,  0.12531172],\n",
              "        ...,\n",
              "        [-0.02556891,  0.08455297,  0.16032362, ..., -0.11467008,\n",
              "          0.12520018,  0.13734584],\n",
              "        [-0.03287774,  0.16865532,  0.05618454, ..., -0.03691015,\n",
              "         -0.14103827,  0.4132429 ],\n",
              "        [-0.10675208,  0.18344373, -0.09262165, ...,  0.00097235,\n",
              "         -0.05054358,  0.17414583]], dtype=float32),\n",
              " array([ 0.14664674,  0.12501961,  0.12887803, ...,  0.10123345,\n",
              "         0.10933981, -0.10592081], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4YOw2fjFyfU"
      },
      "source": [
        "decoder1_model.load_weights('/content/drive/MyDrive/Colab/ResultPNA2DecoderModelW.h5')\n",
        "encoder1_model.load_weights('/content/drive/MyDrive/Colab/ResultPNA2EncoderModelW.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As1torELRsxv"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsFLiwePRvlh"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZoQqfBPtKg6"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6foZmcBuRzd_",
        "outputId": "feb9c23c-e832-45b1-ed01-a1d8fed7376c"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: bhabruvahan son of arjun and chitrangadha\n",
            "Actual Hindi Translation:  बभ्रुवाहन अर्जुन एवं चित्रांग्दा का पुत्र। \n",
            "Predicted Hindi Translation:  बभ्रुवाहन अर्जुन एवं चित्रांग्दा का पुत्र। \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aid7gSvnCjke",
        "outputId": "0910e691-ffa6-4b63-c452-e0e3ca1f87da"
      },
      "source": [
        "# type(decoded_sentence.split())\n",
        "y =y_train[k:k+1].values[0][6: -4].split()\n",
        "Y= decoded_sentence[:-4].split()\n",
        "# print(type(y), type(Y))\n",
        "print('BLEU-1: %f' % corpus_bleu(y, Y, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(y, Y, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(y, Y, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(y, Y, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "# type(y_train.to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.945946\n",
            "BLEU-2: 0.972598\n",
            "BLEU-3: 0.981829\n",
            "BLEU-4: 0.986204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJVl9nNs9L9U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUksdbLwqoGP"
      },
      "source": [
        "help(corpus_bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vqo-6jSR2Dm"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhgnyZRcR41N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0776cbd4-f133-4418-f17f-350dd67be8f6"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: in india there were million pigs in\n",
            "Actual Hindi Translation:  भारत में में लाख सूअर थे \n",
            "Predicted Hindi Translation:  भारत में में लाख सूअर थे \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FL2gMBWR5j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e90c69-cbf3-421f-e125-e90e2e51a2ad"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: today this dish has become the alternative meaning of indian dishes abroad\n",
            "Actual Hindi Translation:  आज तो यूरोपियन देशों में करी इंडियन डिशेस का पर्याय बन गया है। \n",
            "Predicted Hindi Translation:  आज तक तो प्रेमचंद की जनसंख्या का महत्वपूर्ण हि\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-MmdBtptof9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fcf2ec-590f-4ad5-ac8e-04c6fd8152c3"
      },
      "source": [
        "print('Individual 1-gram: %f' % corpus_bleu(y, Y))\n",
        "print('Individual 2-gram: %f' % corpus_bleu(y, Y))\n",
        "print('Individual 3-gram: %f' % corpus_bleu(y, Y))\n",
        "print('Individual 4-gram: %f' % corpus_bleu(y, Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual 1-gram: 0.993527\n",
            "Individual 2-gram: 0.993527\n",
            "Individual 3-gram: 0.993527\n",
            "Individual 4-gram: 0.993527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouOxDfzm6r6R"
      },
      "source": [
        "#urlTest2 = 'https://raw.githubusercontent.com/prismspeechproject/neural/testing/implementation/TestDataset/WordLen3.csv'\n",
        "word3Df =lines[lines['length_eng_sentence']==3]\n",
        "# lines=lines[lines['length_hin_sentence']<=20]\n",
        "x_word3Df = word3Df['English']\n",
        "y_word3Df = word3Df['Hindi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdMsxrKg-QGF"
      },
      "source": [
        "word_gen = generate_batch(x_word3Df, y_word3Df, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb_HheUT-WP3",
        "outputId": "189206da-2cba-40e2-dbd1-2c072b75b15b"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(word_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_word3Df[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_word3Df[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "y =y_word3Df[k:k+1].values[0][6: -4].split()\n",
        "Y= decoded_sentence[:-4].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: languages contain patterns\n",
            "Actual Hindi Translation:  भाषाओं में पैटर्न होते हैं। \n",
            "Predicted Hindi Translation:  भाषाओं में पैटर्न होते हैं। \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93noN1BN-nYT",
        "outputId": "7ce81461-4f11-4826-ae18-5dae81f270b8"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu(y, Y, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(y, Y, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(y, Y, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(y, Y, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "######  3 word result ########### "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.956522\n",
            "BLEU-2: 0.978019\n",
            "BLEU-3: 0.985438\n",
            "BLEU-4: 0.988949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SfFXhks_Tpw"
      },
      "source": [
        "word4Df =lines[lines['length_eng_sentence']==4]\n",
        "# lines=lines[lines['length_hin_sentence']<=20]\n",
        "x_word4Df = word4Df['English']\n",
        "y_word4Df = word4Df['Hindi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w6d2x5g_svA"
      },
      "source": [
        "word4_gen = generate_batch(x_word4Df, y_word4Df, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRLzRDNK_1dk",
        "outputId": "db197597-47f2-4aba-83ea-1a4e1a84a515"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(word4_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_word4Df[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_word4Df[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "y =y_word4Df[k:k+1].values[0][6: -4].split()\n",
        "Y= decoded_sentence[:-4].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: started as a teenager\n",
            "Actual Hindi Translation:  एक किशोर बालिका के रूप में शुरू हुई \n",
            "Predicted Hindi Translation:  एक किशोर बालिका के रूप में शुरू हुई \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKOa2e9HABB4",
        "outputId": "ce160310-0df3-4d6d-91e9-89eb1c49ad7f"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu(y, Y, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(y, Y, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(y, Y, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(y, Y, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "######  4 word result ########### "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.964286\n",
            "BLEU-2: 0.981981\n",
            "BLEU-3: 0.988070\n",
            "BLEU-4: 0.990949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HsdsHpPAI86"
      },
      "source": [
        "word5Df =lines[lines['length_eng_sentence']==5]\n",
        "# lines=lines[lines['length_hin_sentence']<=20]\n",
        "x_word5Df = word5Df['English']\n",
        "y_word5Df = word5Df['Hindi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZgkZ49HAa5L"
      },
      "source": [
        "word5_gen = generate_batch(x_word5Df, y_word5Df, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIhsyzZ1Afkt",
        "outputId": "e42aa2e9-7b27-4ef4-ae6d-d6f58c444667"
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(word5_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_word5Df[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_word5Df[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "y =y_word5Df[k:k+1].values[0][6: -4].split()\n",
        "Y= decoded_sentence[:-4].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: every politician in every country\n",
            "Actual Hindi Translation:  हर देश के राजनेता \n",
            "Predicted Hindi Translation:  हर देश के राजनेता \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADK3UL2YAp5_",
        "outputId": "8cd01a5a-4723-476d-957d-1cb45eaaf738"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu(y, Y, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(y, Y, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(y, Y, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(y, Y, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "######  5 word result ########### "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.928571\n",
            "BLEU-2: 0.963624\n",
            "BLEU-3: 0.975841\n",
            "BLEU-4: 0.981644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNrW8ODdAsoc",
        "outputId": "d501cdca-6664-427c-cbd7-d1b6cd6d75aa"
      },
      "source": [
        "print('BLEU-1: %f' % corpus_bleu(y, Y, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(y, Y, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(y, Y, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(y, Y, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.928571\n",
            "BLEU-2: 0.963624\n",
            "BLEU-3: 0.975841\n",
            "BLEU-4: 0.981644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLb1cMQVBDO_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}